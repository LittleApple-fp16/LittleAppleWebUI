import io
import logging
import sys
import time
import os
import re
import random
import json
import glob
import argparse
from typing import Literal, cast
try:
    import matplotlib
    import gradio as gr
    import numpy
    import webbrowser
    import asyncio
    import tkinter as tk
    from tkinter import filedialog
    import cv2
    import shutil
    from gradio_client import Client
    from pykakasi import kakasi
    from loguru import logger
    from pypinyin import lazy_pinyin
    from PicImageSearch.model import Ascii2DResponse
    from PicImageSearch import Ascii2D, Network
    from littleapple.refresh_token import get_ref_token
    from littleapple.image_link import get_image_links, download_link
    from littleapple.kemono_dl.main import downloader as kemono_dl
    from littleapple.kemono_dl.args import get_args as kemono_args
    from littleapple.train import run_train_plora
    from littleapple.exceptions import DatasetTypeError
    from pixivpy3 import AppPixivAPI, PixivError
    from tqdm import tqdm
    from tqdm.contrib import tzip
    from waifuc.action import HeadCountAction, AlignMinSizeAction, CCIPAction, ThreeStageSplitAction, ModeConvertAction, ClassFilterAction, PersonSplitAction, TaggingAction, RatingFilterAction, NoMonochromeAction, RandomFilenameAction, FirstNSelectAction, FilterSimilarAction, FileExtAction
    from waifuc.export import SaveExporter, TextualInversionExporter
    from waifuc.source import GelbooruSource, PixivSearchSource, ZerochanSource, LocalSource, GcharAutoSource

    from ditk import logging
    from hbutils.system import TemporaryDirectory
    from cyberharem.dataset import save_recommended_tags
    from cyberharem.publish import find_steps_in_workdir
    from cyberharem.utils import get_hf_fs as cyber_get_hf_fs
    from cyberharem.utils import download_file as cyber_download_file
    from cyberharem.publish.civitai import civitai_publish_from_hf
    from cyberharem.publish.huggingface import deploy_to_huggingface
    from huggingface_hub import hf_hub_url
    from huggingface_hub._login import login as hf_login
    from cyberharem.infer.draw import _DEFAULT_INFER_MODEL
    from kohya.train_network import kohya_train_lora

    from PIL import Image
    from imgutils.data import load_image, load_images, rgb_encode, rgb_decode
    from imgutils.tagging import get_wd14_tags, get_mldanbooru_tags, drop_blacklisted_tags, drop_overlap_tags, tags_to_text
    from imgutils.metrics import ccip_difference, ccip_clustering, lpips_clustering
    from imgutils.operate import censor_areas, squeeze, squeeze_with_transparency
    from imgutils.detect import detect_faces, detect_heads, detection_visualize, detect_person
    from imgutils.segment import segment_rgba_with_isnetis
    from imgutils.ocr import detect_text_with_ocr
    from cyberharem.publish.convert import convert_to_webui_lora
except ModuleNotFoundError as e:
    print(f"[è‡´å‘½é”™è¯¯] - æ£€æµ‹åˆ°æ¨¡å—ä¸¢å¤±: {e}ï¼Œ æ­£åœ¨å°è¯•å®‰è£…ä¾èµ–ï¼Œè¯·ç­‰å¾…å®‰è£…å®Œæˆåå†æ¬¡æ‰“å¼€")
    import subprocess
    if os.name == 'nt':
        subprocess.run(['dependencies.bat'], check=True)
    elif os.name == 'posix':
        subprocess.run(['dependencies.sh'], check=True)
    else:
        print("[é”™è¯¯] - æœªçŸ¥çš„æ“ä½œç³»ç»Ÿ")


def download_images(source_type, character_name, p_min_size, p_background, p_class, p_rating, p_crop_person, p_ccip, p_auto_tagging, num_images, p_ai):
    global output_cache
    actions = []
    rating_map = {0: 'safe', 1: 'r15', 2: 'r18'}
    # ratings_to_filter = set(rating_map.values()) - set([rating_map[i] for i in p_rating if i in rating_map])
    ratings_to_filter = set([rating_map[i] for i in p_rating if i in rating_map])
    gr.Info("å¼€å§‹è·å–æ•°æ®é›†")
    logger.info("\n - å¼€å§‹è·å–æ•°æ®é›†")
    character_list = character_name.split(',')
    for character in character_list:
        character = character.replace(' ', '_')  # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        save_path = 'dataset/' + character
        if source_type == 'Gelbooru':
            source_init = GelbooruSource([character, 'solo'])
        elif source_type == 'Pixiv':
            if not cfg.get('pixiv_token', ''):
                gr.Warning("Pixivæœªç™»å½•")
                return "Pixivè®¿é—®ä»¤ç‰Œæœªè®¾ç½®"
            source_init = PixivSearchSource(
                character,
                no_ai=p_ai,
                refresh_token=cfg.get('pixiv_token', '')
            )
            # actions.append(CCIPAction())
        elif source_type == 'Zerochan':
            source_init = ZerochanSource([character, 'solo'])
        else:  # è‡ªåŠ¨
            source_init = GcharAutoSource(character, pixiv_refresh_token=cfg.get('pixiv_token', ''))
            # actions.append(CCIPAction())
        if p_class:
            if 0 in p_class:
                actions.append(NoMonochromeAction())
            if 1 in p_class:
                actions.append(ClassFilterAction(['illustration', 'bangumi']))
            # class_to_filter = set(class_map.values()) - set([class_map[i] for i in p_class if i in class_map])
            # class_to_filter = set([class_map[i] for i in p_class if i in class_map])
        if int(num_images) >= 64 and p_ccip:
            actions.append(CCIPAction())
        if p_crop_person:
            actions.append(PersonSplitAction())
        if p_auto_tagging:
            actions.append(TaggingAction(force=True))
        if p_min_size:
            # logger.debug(int(p_min_size))
            actions.append(AlignMinSizeAction(min_size=int(p_min_size)))
        actions.append(FilterSimilarAction('all'))  # lpipså·®åˆ†è¿‡æ»¤
        actions.append(ModeConvertAction('RGB', p_background))
        actions.append(HeadCountAction(1))
        # actions.append(RandomFilenameAction(ext='.png'))
        actions.append(FileExtAction(ext='.png'))  # pngæ ¼å¼è´¨é‡æ— æŸ
        # logger.debug(cast(list[Literal['safe', 'r15', 'r18']], list(ratings_to_filter)))
        if ratings_to_filter != set(rating_map.values()):
            actions.append(RatingFilterAction(ratings=cast(list[Literal['safe', 'r15', 'r18']], list(ratings_to_filter))))
        actions.append(FirstNSelectAction(int(num_images)))
        if source_type == 'Gelbooru' and not p_auto_tagging:
            source_init.attach(*actions).export(  # åªä¸‹è½½å‰num_imageså¼ å›¾ç‰‡
                SaveExporter(save_path)  # å°†å›¾ç‰‡ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
            )
        else:
            source_init.attach(*actions).export(  # åªä¸‹è½½å‰num_imageså¼ å›¾ç‰‡
                TextualInversionExporter(save_path)  # å°†å›¾ç‰‡ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
            )
        # logger.debug(ratings_to_filter)
    gr.Info("æ•°æ®é›†è·å–å·²ç»“æŸ")
    output_cache = []
    return "å·²è·å–æ•°æ®é›†"


def dataset_getImg(dataset_name, rep_name=None):  # ç¡®ä¿æ¯ä¸ªæ–¹æ³•ä¸­åªè°ƒç”¨ä¸€æ¬¡ ç”±äºtqdm
    global output_cache
    logger.info(" - åŠ è½½æ•°æ®é›†å›¾åƒ...")
    if dataset_name.endswith(' (kohya)'):
        dataset_path = f'dataset/_kohya/{dataset_name.replace(" (kohya)", "")}/{rep_name}'
    else:
        dataset_path = f"dataset/{dataset_name}"
    images = []
    img_name = []
    for filename in os.listdir(dataset_path):
        if filename.endswith(('.png', '.jpg', '.jpeg')):
            img = Image.open(os.path.join(dataset_path, filename))
            if img is not None:
                images.append(img)
                img_name.append(filename)
    # output_cache = images
    images = load_images(images)
    return images, img_name


def download_illust(i_name, i_source, i_maxsize=None):
    global pyapi
    global cfg
    global output_cache
    gr.Info("å¼€å§‹è·å–æ•°æ®é›†")
    maxsize = round(float(i_maxsize), 1) if i_maxsize else None
    try:
        json_result = pyapi.search_user(i_name)
        illust = json_result.user_previews[0].illusts[0]
        kemono_arg = kemono_args()
        kemono_arg["cookies"] = {k: str(v) for k, v in json.loads(cfg['fanbox_cookie']).items()}
        kemono_arg["links"] = ["https://kemono.su/fanbox/user/" + str(illust['user']['id'])]
        kemono_arg["dirname_pattern"] = f"dataset/{i_name}"
        kemono_arg["max_filesize"] = maxsize
        kemono_arg["retry"] = 3
        if cfg.get('proxie_enabled', False):
            kemono_arg["proxie"] = {
                'http': 'http://' + cfg.get('proxie_ip', None) + ':' + cfg.get('proxie_port', None)
            }
        if 0 in i_source:
            logger.info("[ä¿¡æ¯] - ç”»å¸ˆå†…å®¹è·å–éœ€è¦ä¸€æ®µæ—¶é—´")
            links = get_image_links(illust['user']['id'], maxsize)
            for url, name in tzip(links[0], links[1], file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - å¼€å§‹ä¸‹è½½"):
                if not os.path.exists(f"dataset/{illust['user']['name']}"):
                    os.makedirs(f"dataset/{illust['user']['name']}")
                download_link(url, f"dataset/{illust['user']['name']}/{name}.png")
        # print(">>> %s, origin url: %s" % (illust.title, illust.image_urls['large']))
        # return "å·²è·å–"+illust['user']['name']+"ç”»å¸ˆæ•°æ®é›†"
        if 1 in i_source:
            kemono_dl(kemono_arg)
        gr.Info(i_name+" æ•°æ®é›†è·å–å·²ç»“æŸ")
        output_cache = []
        return "ä¸‹è½½å·²ç»“æŸ"
    except Exception as exp:
        gr.Warning("æ•°æ®é›†è·å–å¤±è´¥, è¯·æŸ¥çœ‹æ§åˆ¶å°")
        logger.error(f"[é”™è¯¯] - è·å–å¤±è´¥\nä½ å¿…é¡»è®¾ç½®Pixivè®¿é—®ä»¤ç‰Œæ‰èƒ½è·å–Pixivçš„å†…å®¹\nä½ å¿…é¡»è®¾ç½®Kemonoä»¤ç‰Œæ‰èƒ½è·å–Fanboxçš„å†…å®¹\nä½ å¿…é¡»è¾“å…¥æ­£ç¡®çš„ç”»å¸ˆå, é”™è¯¯ä¿¡æ¯:{exp}")
        output_cache = []
        return "è·å–å¤±è´¥\nä½ å¿…é¡»è®¾ç½®Pixivè®¿é—®ä»¤ç‰Œæ‰èƒ½è·å–Pixivçš„å†…å®¹\nä½ å¿…é¡»è®¾ç½®Kemonoä»¤ç‰Œæ‰èƒ½è·å–Fanboxçš„å†…å®¹\nä½ å¿…é¡»è¾“å…¥æ­£ç¡®çš„ç”»å¸ˆå"


def get_fanbox_cookie():
    webbrowser.open(f"https://kemono.su/account/login")


global gelbooru_fast_settings


# def get_danbooru_fast(tags):
#     batches = tags.split("|")
#     global danbooru_fast_settings
#
#     for i, batch in enumerate(batches):
#         # settings = DanbooruSpider.settings
#         danbooru_fast_settings = {
#             'assistant': "danbooru_crawler",
#             'SEARCH_KEYS': "group_sex+doggystyle",
#             'SPIDER_MODULES': ["danbooru_crawler.spiders"],
#             'NEWSPIDER_MODULE': "danbooru_crawler.spiders",
#             'ROBOTSTXT_OBEY': False,
#             'REQUEST_FINGERPRINTER_IMPLEMENTATION': "2.7",
#             'TWISTED_REACTOR': "twisted.internet.asyncioreactor.AsyncioSelectorReactor",
#             'FEED_EXPORT_ENCODING': "utf-8",
#             'CONCURRENT_REQUESTS': 32,
#             'DOWNLOAD_DELAY': 1,
#             'ITEM_PIPELINES': {'scrapy.pipelines.images.ImagesPipeline': 1},
#             'IMAGES_STORE': '../dataset/test',  # è®¾ç½®å›¾ç‰‡å­˜å‚¨è·¯å¾„
#         }
#         name = batch.replace(" ", "_")
#         danbooru_fast_settings['IMAGES_STORE'] = f'../dataset/{name}'
#         tag = name.replace(",", "+")
#         danbooru_fast_settings['SEARCH_KEYS'] = tag
#         with open('tmp.bin', 'wb') as tmp:
#             pickle.dump(danbooru_fast_settings, tmp)
#         # execute(["scrapy", "crawl", "danbooru"])
#         # process = multiprocessing.Process(target=CrawlerProcess(danbooru_fast_settings))
#         # process.crawl(DanbooruSpider.DanbooruSpider, tag=tag)
#         # process.start()
#         # reactor.run()
#         DanbooruSpider.__main__()


def has_image(got_list):
    if any(isinstance(item, Image.Image) for item in got_list):
        return True
    else:
        return False


def has_area(got_list):
    if not got_list:
        return False
    if isinstance(got_list, list) and all(
        isinstance(item, list) and len(item) == 1 and
        isinstance(item[0], tuple) and len(item[0]) == 3 and
        isinstance(item[0][0], tuple) and len(item[0][0]) == 4 and
        all(isinstance(n, int) for n in item[0][0]) and
        isinstance(item[0][1], str) and
        isinstance(item[0][2], float)
        for item in got_list
    ):
        return True
    return False


def get_output_status(o_cache):
    if has_image(o_cache):
        return "æš‚å­˜å›¾åƒç»“æœ"+"["+str(len(o_cache))+"] | "
    elif has_area(o_cache):
        return "æš‚å­˜åŒºåŸŸç»“æœ"+"["+str(len(o_cache))+"] | "
    elif not o_cache:
        return "è¿è¡Œç»“æœæ˜¯ç©ºçš„ | "
    else:
        return "è¿è¡Œç»“æœå¼‚å¸¸ | "


async def illu_getter(pic):
    global cfg
    global output_cache
    gr.Info("å¼€å§‹è·å–ç”»å¸ˆä¿¡æ¯")
    if cfg.get('proxie_enabled', False):
        proxies = 'http://'+cfg.get('proxie_ip', None)+':'+cfg.get('proxie_port', None)
    else:
        proxies = None
    async with Network(proxies=proxies) as client:
        ascii2d = Ascii2D(
            client=client
        )
        resp = await ascii2d.search(file=pic)
        selected = None
        for i in resp.raw:
            if i.author_url.startswith("https://www.pixiv.net/users/"):
                selected = i
                break
        if selected is None:
            output_cache = []
            gr.Warning("æœªæ‰¾åˆ°å¯¹åº”ç”»å¸ˆ")
            return "æœªæ‰¾åˆ°", ""
        else:
            output_cache = []
            gr.Info("ç”»å¸ˆ "+selected.author+"çš„ä½œå“ "+selected.title)
            return selected.author + " (" + selected.author_url + ") " + "çš„ä½œå“:" + selected.title, selected.author  # re.search(r'\d+$', selected.author_url).group()


def clustering(dataset_name, thre, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    # print(clusters)
    clustered_imgs = []
    added_clusters = set()  # åˆ›å»ºä¸€ä¸ªé›†åˆ å…¶ä¸­å­˜å‚¨å·²ç»æ·»åŠ è¿‡çš„æ ‡ç­¾ æ­¤é›†åˆå°†çº¦æŸè¢«è¿‡æ»¤çš„imgåˆ—è¡¨ é›†åˆä¸­çš„å…ƒç´ æ— æ³•dup
    # print(" - å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç†")
    for i, cluster in enumerate(tqdm(lpips_clustering(images, thre), file=sys.stdout, desc=" - å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ")):  # èšç±»æ–¹æ³• -1è¡¨ç¤ºnoiseï¼Œä¸sklearnä¸­çš„ç›¸åŒ
        if cluster == -1:
            clustered_imgs.append(images[i])
        elif cluster not in added_clusters:
            clustered_imgs.append(images[i])
            added_clusters.add(cluster)
    gr.Info("å·®åˆ†è¿‡æ»¤å·²ç»“æŸ")
    output_cache = clustered_imgs
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: å·®åˆ†è¿‡æ»¤"


def three_stage(dataset_name, rep_name=None):
    gr.Info("ä¸‰é˜¶åˆ†å‰²å¼€å§‹å¤„ç†")
    global output_cache
    if not dataset_name.endswith(' (kohya)'):
        if dataset_name.endswith("_processed"):
            process_dir = f"dataset/{dataset_name}"
        else:
            process_dir = f"dataset/{dataset_name}_processed"
        local_source = LocalSource(f"dataset/{dataset_name}")
        local_source.attach(
            ThreeStageSplitAction(),
        ).export(TextualInversionExporter(process_dir, True))
    else:
        if re.search(r'\d+_(.*)', rep_name) == 'processed':
            pass
        local_source = LocalSource(f'dataset/_kohya/{dataset_name.replace(" (kohya)", "")}/{rep_name}')
        repeat = int(re.search(r'(\d+)_.*', rep_name).group(1)//2)
        local_source.attach(
            ThreeStageSplitAction(),
        ).export(TextualInversionExporter(f'dataset/_kohya/{dataset_name.replace(" (kohya)", "")}/{str(repeat) if repeat != 0 else str(1)}_processed', True))

    gr.Info("ä¸‰é˜¶åˆ†å‰²å·²ç»“æŸ")
    output_cache = []
    return "å·²ä¿å­˜è‡³"+process_dir+"æ–‡ä»¶å¤¹"

# def person_detect(dataset_name, level, version, max_infer_size, conf_threshold, iou_threshold):
#     global output_cache
#     images = dataset_getImg(dataset_name)[0]
#     detected = []
#     if level:
#         level = "m"
#     else:
#         level = "n"
#     print(" - äººç‰©æ£€æµ‹å¼€å§‹å¤„ç†")
#     for img in tqdm(images):
#         detected.append(detect_person(img, level, version, max_infer_size, conf_threshold, iou_threshold))
#     output_cache = detected
#     return detected


def face_detect(dataset_name, level, version, max_infer_size, conf_threshold, iou_threshold, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    detected = []
    if level:
        level = "s"
    else:
        level = "n"
    # print(" - é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†")
    # print("   *å°†è¿”å›åŒºåŸŸç»“æœ")
    for img in tqdm(images, file=sys.stdout, desc=" - é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        detected.append(detect_faces(img, level, version, max_infer_size, conf_threshold, iou_threshold))
    gr.Info("é¢éƒ¨æ£€æµ‹å·²ç»“æŸ")
    output_cache = detected
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: é¢éƒ¨æ£€æµ‹"


def head_detect(dataset_name, level, max_infer_size, conf_threshold, iou_threshold, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    detected = []
    if level:
        level = "s"
    else:
        level = "n"
    # print(" - å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†")
    # print("   *å°†è¿”å›åŒºåŸŸç»“æœ")
    for img in tqdm(images, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†"):
        detected.append(detect_heads(img, level, max_infer_size, conf_threshold, iou_threshold))
    gr.Info("å¤´éƒ¨æ£€æµ‹å·²ç»“æŸ")
    output_cache = detected
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: å¤´éƒ¨æ£€æµ‹"


def text_detect(dataset_name, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("æ–‡æœ¬æ£€æµ‹å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("æ–‡æœ¬æ£€æµ‹å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    detected = []
    for img in tqdm(images, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ–‡æœ¬æ£€æµ‹å¼€å§‹å¤„ç†"):
        detected.append(detect_text_with_ocr(img))
    gr.Info("æ–‡æœ¬æ£€æµ‹å·²ç»“æŸ")
    output_cache = detected
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: æ–‡æœ¬æ£€æµ‹"


def area_fill(dataset_name, is_random, color, rep_name=None):
    global output_cache
    area = output_cache
    gr.Info("åŒºåŸŸå¡«å……å¼€å§‹å¤„ç†")
    images = dataset_getImg(dataset_name, rep_name)[0]
    fill = []
    xyxy = []
    # print(" - åŒºåŸŸå¡«å……å¼€å§‹å¤„ç†")
    for img, xyxys in tzip(images, area, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - åŒºåŸŸå¡«å……å¼€å§‹å¤„ç†"):
        if xyxys:
            for exy in [xyxys][0]:
                xyxy.append(exy[0])
        if is_random:
            color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
            color = random.choice(color)
            # color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
        # print(img, eval(area), xyxys, xyxys[0][0])
        fill.append(censor_areas(img, 'color', xyxy, color=color))  # [xyxys[0][0]]
    # os.makedirs(f"processed/{dataset_name}", exist_ok=True)
    # for i, sv in enumerate(fill):
    #     sv.save(f"processed/{dataset_name}/{dataset_name}_AreaFill_{i+1}.png")
    gr.Info("åŒºåŸŸå¡«å……å·²ç»“æŸ")
    output_cache = fill
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: åŒºåŸŸå¡«å……"


def area_blur(dataset_name, rad, rep_name=None):
    global output_cache
    area = output_cache
    gr.Info("åŒºåŸŸæ¨¡ç³Šå¼€å§‹å¤„ç†")
    images = dataset_getImg(dataset_name, rep_name)[0]
    blur = []
    xyxy = []
    for img, xyxys in tzip(images, area, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - åŒºåŸŸæ¨¡ç³Šå¼€å§‹å¤„ç†"):
        if xyxys:
            for exy in [xyxys][0]:
                xyxy.append(exy[0])
            blur.append(censor_areas(img, 'blur', xyxy, radius=rad))
        else:
            blur.append(img)
    output_cache = blur
    gr.Info("åŒºåŸŸæ¨¡ç³Šå·²ç»“æŸ")
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: åŒºåŸŸæ¨¡ç³Š"


def crop_hw(dataset_name, rep_name=None):
    global output_cache
    mask_info = output_cache
    gr.Info("åŒºåŸŸå‰ªè£å¼€å§‹å¤„ç†")
    images = dataset_getImg(dataset_name, rep_name)[0]
    result = []
    for img, infos in zip(images, mask_info):
        # infos = infos[0]
        # logger.debug(infos)
        for einfo in infos:
            (x0, y0, x1, y1) = einfo[0]
            detect_type = einfo[1]
            # score = infos[2]
            img_array = numpy.array(rgb_encode(img))
            h, w = img_array.shape[1:]
            mask = numpy.zeros((h, w))
            # print(mask, h, w)
            if detect_type == 'face' or detect_type == 'head' or detect_type == 'text':
                mask[y0:y1, x0:x1] = 1
                # print(mask)
            else:
                output_cache = []
                gr.Warning("åŒºåŸŸå‰ªè£: å½“å‰è¿è¡Œç»“æœä¸æ”¯æŒå‰ªè£")
                return "æ­¤å†…å®¹ä¸æ”¯æŒå‰ªè£"
            result.append(squeeze(img, mask))
    output_cache = result
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: åŒºåŸŸå‰ªè£"


def crop_trans(dataset_name, threshold, filter_size, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("è‡ªé€‚åº”å‰ªè£å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("è‡ªé€‚åº”å‰ªè£å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    out = []
    for img in tqdm(images, file=sys.stdout, desc=" - è‡ªé€‚åº”å‰ªè£å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        if img is not None:
            out.append(squeeze_with_transparency(img, threshold, filter_size))
    gr.Info("è‡ªé€‚åº”å‰ªè£å·²ç»“æŸ")
    output_cache = out
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: è‡ªé€‚åº”å‰ªè£"


def img_segment(dataset_name, scale, rep_name=None):
    global output_cache
    if has_image(output_cache):
        images = output_cache
        gr.Info("äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç† <- ç¼“å­˜")
    else:
        images = dataset_getImg(dataset_name, rep_name)[0]
        gr.Info("äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç† <- æ•°æ®é›†")
    out = []
    # print(" - äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç†")
    for img in tqdm(images, file=sys.stdout, desc=" - äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        out.append(segment_rgba_with_isnetis(img, scale)[1])  # maskä¿¡æ¯è¢«ä¸¢å¼ƒäº†
    gr.Info("äººç‰©åˆ†ç¦»å·²ç»“æŸ")
    output_cache = out
    return get_output_status(output_cache)+"ä¸Šæ¬¡æ“ä½œ: äººç‰©åˆ†ç¦»"


def ref_datasets(need_list=False):
    # éå†æœ¬åœ°æ•°æ®é›†
    list_datasets = []
    with os.scandir("dataset") as datasets:
        for each_dataset in datasets:
            if not each_dataset.name.startswith('.') and each_dataset.is_dir():
                if each_dataset.name == '_kohya':
                    with os.scandir(each_dataset) as kohya_datasets:
                        for kohya_dataset in kohya_datasets:
                            if not kohya_dataset.name.startswith('.') and kohya_dataset.is_dir():
                                list_datasets.append(kohya_dataset.name + ' (kohya)')
                else:
                    list_datasets.append(each_dataset.name)
    if need_list:
        return list_datasets
    else:
        gr.Info("æ•°æ®é›†å·²æ›´æ–°")
        return gr.update(choices=list_datasets)


def ref_kohya_rep(kohya_dataset, need_list=False):
    list_reps = []
    if kohya_dataset.endswith(' (kohya)'):
        with os.scandir(f'dataset/_kohya/{kohya_dataset.replace(" (kohya)", "")}') as dataset:
            for each_rep in dataset:
                if re.match(r"\d+_", each_rep.name) and each_rep.is_dir():
                    list_reps.append(each_rep.name)
        if need_list:
            return list_reps
        else:
            return gr.update(choices=list_reps, visible=True, value=list_reps[0])
    else:
        if need_list:
            return []
        else:
            gr.Warning("æ•°æ®é›†ç±»å‹é”™è¯¯")
            return gr.update(choices=None)


def ref_customList(need_list=False):
    custom_blacklist = []
    with os.scandir("cfgs/blacklist") as blacklists:
        for each_black in blacklists:
            if not each_black.name.startswith('.') and each_black.is_file():
                if each_black.name.endswith('.txt') or each_black.name.endswith('.json'):
                    custom_blacklist.append(each_black.name)
    if need_list:
        return custom_blacklist
    else:
        gr.Info("æ ‡ç­¾é»‘åå•å·²æ›´æ–°")
        return gr.update(choices=custom_blacklist)


def ref_runs(dataset_name, need_list=False):
    runs_list = []
    try:
        with os.scandir(f"runs/{dataset_name}/ckpts") as conv_list:
            for conv in conv_list:
                # print("éå†äº†ä¸€ä¸ªconv")
                if conv.is_file():
                    if conv.name.endswith('.pt') and not dataset_name == '_kohya':
                        runs_list.append(conv.name.replace(dataset_name+"-", "").replace(".pt", ""))
    except FileNotFoundError:
        if need_list:
            return []
        else:
            return gr.update(choices=[])
    if runs_list is not None:
        runs_list = sorted(runs_list, key=int, reverse=True)
        if need_list:
            return runs_list
        else:
            gr.Info("è®­ç»ƒç»“æœå·²æ›´æ–°")
            # print("ç»“æœ"+str(runs_list))
            return gr.update(choices=runs_list)


def run_train_lora(dataset_name, epoch, bs, toml_index, is_pipeline=False):
    logger.info("LoRAå¼€å§‹è®­ç»ƒ")
    gr.Info(f"[{dataset_name}] LoRAå¼€å§‹è®­ç»ƒ")
    if not is_pipeline:
        if not dataset_name.endswith(' (kohya)'):  # from dataset_dropdown
            raise DatasetTypeError(dataset_name, "æ­£åœ¨å°è¯•åŠ è½½kohyaæ•°æ®é›†")
        else:
            r_dataset_name = dataset_name.replace(" (kohya)", "")
        kohya_train_lora(f"dataset/_kohya/{r_dataset_name}", r_dataset_name, f"runs/_kohya/{r_dataset_name}", epoch, bs, toml_index)
        for folder_name in os.listdir(f"dataset/_kohya/{r_dataset_name}"):
            if re.match(r"\d+_", folder_name):
                save_recommended_tags(f"dataset/_kohya/{r_dataset_name}/{folder_name}", r_dataset_name, f"runs/_kohya/{r_dataset_name}")
    else:
        r_dataset_name = dataset_name
        kohya_train_lora(f"pipeline/dataset/_kohya/{r_dataset_name}", r_dataset_name, f"pipeline/runs/_kohya/{r_dataset_name}", epoch, bs, toml_index)
        save_recommended_tags(f"pipeline/dataset/_kohya/{r_dataset_name}/1_{r_dataset_name}", r_dataset_name, f"pipeline/runs/_kohya/{r_dataset_name}")
    return "LoRAè®­ç»ƒå®Œæˆ"


def convert_weights(dataset_name, step):
    global output_cache
    gr.Info("å¼€å§‹è½¬æ¢LoRA")
    # logging.try_init_root(logging.INFO)
    convert_to_webui_lora(f"runs/{dataset_name}/ckpts/unet-{step}.safetensors",
                          f"runs/{dataset_name}/ckpts/text_encoder-{step}.safetensors",
                          os.path.join(f"runs/{dataset_name}/ckpts", f"{dataset_name}-lora-{step}.safetensors")
                          )
    gr.Info("LoRAè½¬æ¢å·²ç»“æŸ")
    output_cache = []
    return "å·²æ‰§è¡Œè½¬æ¢"


def tagger_chooser_ctrl(evt: gr.SelectData):  # æ­¤æ–¹æ³•ä½¿ç”¨å…¨å±€å˜é‡
    # print(evt.value+"æ­£åœ¨é€‰æ‹©")
    # éšè—æ‰€æœ‰æ‰“æ ‡å™¨è®¾ç½®
    updates = {}
    for tagger in taggers:
        # if tagger == "æ ‡ç­¾é»‘åå•":
        #     tagger = "dropper"
        if tagger == "jsonè§£æ":
            tagger = "anal"
        updates[globals()[f"tagger_{tagger}_settings"]] = gr.update(visible=False)
    # æ˜¾ç¤ºæ‰“æ ‡å™¨è®¾ç½®
    if evt.value in taggers:
        # if evt.value == "æ ‡ç­¾é»‘åå•":
        #     evt.value = "dropper"
        if evt.value == "jsonè§£æ":
            evt.value = "anal"
        updates[globals()[f"tagger_{evt.value}_settings"]] = gr.update(visible=True)
        # print(evt.value, tagger_dropper_settings.visible)
    # updates[globals()[f"wd14_use_blacklist"]] = gr.update(value=wd14_use_blacklist.value)
    # updates[globals()[f"ml_use_blacklist"]] = gr.update(value=ml_use_blacklist.value)
    # updates[globals()[f"tagger_dropper_settings"]] = gr.update(visible=tagger_dropper_settings.visible)
    return updates


def blacklist_settings_ctrl(evt: gr.SelectData):
    updates = {}
    if evt.selected:
        updates[tagger_dropper_settings] = gr.update(visible=True)
    else:
        updates[tagger_dropper_settings] = gr.update(visible=False)
    return updates


def kohya_rep_ctrl(evt: gr.SelectData):
    updates = {}
    if evt.value.endswith(' (kohya)'):
        updates[kohya_rep_dropdown] = ref_kohya_rep(evt.value)
        updates[ref_rep_button] = gr.update(visible=True)
    else:
        updates[kohya_rep_dropdown] = gr.update(visible=False)
        updates[ref_rep_button] = gr.update(visible=False)
    return updates


def custom_blacklist_ctrl(evt: gr.SelectData):
    if evt.selected:
        dropper_update = {globals()[f"drop_custom_setting"]: gr.update(visible=False)}
    else:
        dropper_update = {globals()[f"drop_custom_setting"]: gr.update(visible=True)}
    return dropper_update


def pixiv_setting_ctrl(evt: gr.SelectData):
    if evt.index == 1:
        update = {globals()[f"pixiv_settings"]: gr.update(visible=True)}
    else:
        update = {globals()[f"pixiv_settings"]: gr.update(visible=False)}
    return update


def color_picker_ctrl(evt: gr.SelectData):
    if evt.selected:
        update = {globals()[f"areaf_color"]: gr.update(visible=False)}
    else:
        update = {globals()[f"areaf_color"]: gr.update(visible=True)}
    return update


def save_output_ctrl():
    global output_cache
    if has_image(output_cache):
        update = {globals()[f"save_output"]: gr.update(interactive=True)}
    else:
        update = {globals()[f"save_output"]: gr.update(interactive=False)}
    return update


def saving_output(dataset_name):
    global output_cache
    count = 0
    if dataset_name.endswith("_processed"):
        process_dir = f"dataset/{dataset_name}"
    else:
        process_dir = f"dataset/{dataset_name}_processed"
    if has_image(output_cache):
        gr.Info("å¼€å§‹ä¿å­˜è¿è¡Œç»“æœ")
        os.makedirs(process_dir, exist_ok=True)
        anyfiles = os.listdir(process_dir)
        # print(" - å¼€å§‹ä¿å­˜è¿è¡Œç»“æœ")
        for anyfile in anyfiles:
            os.remove(f"{process_dir}/{anyfile}")
        for i, sv in enumerate(tqdm(output_cache, file=sys.stdout, desc=" - å¼€å§‹ä¿å­˜è¿è¡Œç»“æœ", ascii="â–‘â–’â–ˆ")):
            sv.save(f"{process_dir}/{dataset_name}_{i+1}.png")
            count = count+1
        gr.Info("å·²ä¿å­˜"+str(count)+" å¼ å›¾åƒè‡³"+process_dir+"æ•°æ®é›†")
        output_cache = []
        return "å·²ä¿å­˜ "+str(count)+" å¼ å›¾åƒè‡³"+process_dir+"æ•°æ®é›†"
    else:
        gr.Warning("æ— æ³•ä¿å­˜: è¿è¡Œç»“æœå†…æ²¡æœ‰å›¾åƒ")


def tagging_main(dataset_name, ttype, wd14_tagger, wd14_general_thre, wd14_character_thre, wd14_weight, wd14_overlap, ml_real_name, ml_thre, ml_scale, ml_weight, ml_ratio, ml_overlap, need_black, drop_presets, drop_custom, exists_txt, del_json, rep_name=None):
    global output_cache
    images = dataset_getImg(dataset_name, rep_name)[0]
    img_name = dataset_getImg(dataset_name, rep_name)[1]
    if ttype == taggers[0]:
        gr.Info("æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç† æ‰“æ ‡å™¨: wd14")
        for img, name in tzip(images, img_name, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†"):
            result = get_wd14_tags(img, wd14_tagger, wd14_general_thre, wd14_character_thre, wd14_overlap)
            if result[2]:
                result = tags_to_text(result[1], include_score=wd14_weight)+', '+tags_to_text(result[2], include_score=wd14_weight)  # features and chars
            else:
                result = tags_to_text(result[1], include_score=wd14_weight)
            if need_black:
                # print(result)
                result = str(str(drop_blacklisted_tags([result], drop_presets, drop_custom))[2:-2])
            if result:
                name = name.replace(".txt", "").replace(".jpg", "").replace(".png", "").replace(".jpeg", "")
                if os.path.isfile(f'dataset/{dataset_name}/{name}.txt'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'dataset/{dataset_name}/{name}.txt', f'{dataset_name}/{name}_backup.txt')
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'a+') as tag:
                            tag.write(result)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                else:
                    with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                        tag.write(result)
        gr.Info("æ•°æ®æ‰“æ ‡å·²ç»“æŸ")
    elif ttype == taggers[1]:
        gr.Info("æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç† æ‰“æ ‡å™¨: mldanbooru")
        # print(" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†")
        for img, name in tzip(images, img_name, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†"):
            result = get_mldanbooru_tags(img, ml_real_name, ml_thre, ml_scale, ml_ratio, ml_overlap)
            result = tags_to_text(result, include_score=ml_weight)
            if need_black:
                result = str(str(drop_blacklisted_tags([result], drop_presets, drop_custom))[2:-2])
            # print(result)
            if result:
                name = name.replace(".txt", "")
                if os.path.isfile(f'dataset/{dataset_name}/{name}.txt'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'dataset/{dataset_name}/{name}.txt', f'{dataset_name}/{name}_backup.txt')
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'a+') as tag:
                            tag.write(result)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                else:
                    with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                        tag.write(result)
        gr.Info("æ•°æ®æ‰“æ ‡å·²ç»“æŸ")
    elif ttype == taggers[2]:
        gr.Info("æ ‡ç­¾è§£æå¼€å§‹å¤„ç†")
        json_files = glob.glob(f'dataset/{dataset_name}/.*.json')
        # print(" - æ ‡ç­¾è§£æå¼€å§‹å¤„ç†")
        for json_file in tqdm(json_files, file=sys.stdout, desc=" - æ ‡ç­¾è§£æå¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
            with open(json_file, 'r') as f:
                jdata = json.load(f)
            danbooru_data = jdata.get('danbooru', {})
            tag_json_general = danbooru_data.get('tag_string_general', '')
            tag_json_character = danbooru_data.get('tag_string_character, ')
            if tag_json_general:
                tag_json_general = tag_json_general.replace(' ', ', ')
            if tag_json_character:
                tag_json_character = tag_json_character.replace(' ', ', ')
            if tag_json_general is None and tag_json_character is None:
                gr.Warning("æ ‡ç­¾è§£æ: æ•°æ®é›†å†…æ— jsonæ ‡ç­¾")
                return get_output_status(output_cache)+"æ ‡ç­¾è§£æå¤±è´¥"
            elif tag_json_general is None:
                tag_json = tag_json_character
            elif tag_json_character is None:
                tag_json = tag_json_general
            else:
                tag_json = f"{tag_json_general}\n{tag_json_character}\n"
            if need_black:
                tag_json = str(str(drop_blacklisted_tags([tag_json], drop_presets, drop_custom))[2:-2])
            txtfile_name = json_file.replace('.', '', 1).replace('_meta.json', '.txt')
            if tag_json_general or tag_json_character:
                if os.path.isfile(f'{txtfile_name}'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'{txtfile_name}', f'{txtfile_name}'.replace('.txt', '_backup.txt'))
                        with open(f'{txtfile_name}', 'w') as f:
                            f.write(tag_json)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'{txtfile_name}', 'a+') as f:
                            f.write(tag_json)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'{txtfile_name}', 'w') as f:
                            f.write(tag_json)
                else:
                    with open(f'{txtfile_name}', 'w') as f:
                        f.write(tag_json)
                if del_json:
                    os.remove(json_file)
        gr.Info("æ ‡ç­¾è§£æå·²ç»“æŸ")


# @gr.StateHandler
def pre_rating_limit(rating):
    updates = {}
    # print(evt.index)
    # print(pre_rating)
    # print(rating)
    if not rating:
        updates[download_button] = gr.update(interactive=False)
    else:
        updates[download_button] = gr.update(interactive=True)
    return updates


# @gr.StateHandler
def illu_source_limit(i_source):
    updates = {}
    if not i_source:
        updates[illu_button] = gr.update(interactive=False)
    else:
        updates[illu_button] = gr.update(interactive=True)
    return updates


def save_settings(p_token, f_cookie, c_token, pro_ip, pro_port, pro_enabled, ver_enabled, thm_light, thm_style):
    global cfg
    cfg['pixiv_token'] = p_token
    cfg['fanbox_cookie'] = f_cookie
    cfg['civitai_token'] = c_token
    cfg['proxie_ip'] = pro_ip
    cfg['proxie_port'] = pro_port
    cfg['proxie_enabled'] = pro_enabled
    cfg['verify_enabled'] = ver_enabled
    cfg['theme_light'] = 'Light' if thm_light == 'äº®è‰²' else 'Dark'
    cfg['theme_style'] = thm_style if not thm_style == 'é»˜è®¤' else 'Default'
    with open('config.json', 'w') as f:
        json.dump(cfg, f, ensure_ascii=False, indent=4)
    gr.Info("è®¾ç½®å·²ä¿å­˜")
    load_settings()
    # åˆ·æ–°è®¾ç½®é¡µé¢
    return get_output_status(output_cache)+"è®¾ç½®å·²ä¿å­˜"


def load_settings():
    global cfg
    if os.path.getsize('config.json') > 0:  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        with open('config.json', 'r') as config:
            cfg = json.load(config)
    else:
        cfg = {}
    gr.Info("è®¾ç½®å·²è¯»å–")


def load_css():
    global cfg
    css_files = []
    merged_css = ""
    if cfg.get('theme_style', 'Default') == 'NovelAI':
        css_files.append('style/novel.css')
    css_files.append('style/apple.css')
    if css_files:
        for css_file in css_files:
            with open(css_file, "r") as f:
                css_content = f.read()
            merged_css += css_content
    logger.success("å·²åŠ è½½css")
    return merged_css


def pixiv_login():
    global pyapi
    global cfg
    pyapi = AppPixivAPI()
    for _ in range(3):
        try:
            pyapi.auth(refresh_token=cfg.get('pixiv_token', ''))
            gr.Info("Pixivå·²ç™»å½•")
            logger.success("[ä¿¡æ¯] - Pixivç™»å½•æˆåŠŸ")
            break
        except PixivError:
            time.sleep(10)
        if not cfg.get('pixiv_token', ''):
            gr.Warning("Pixivç™»å½•å¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰è®¾ç½®è®¿é—®ä»¤ç‰Œ")
            logger.warning("[è­¦å‘Š] - Pixivç™»å½•å¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰è®¾ç½®è®¿é—®ä»¤ç‰Œ")
            break
    else:
        gr.Warning("Pixivç™»å½•å¤±è´¥")
        logger.warning("[è­¦å‘Š] - Pixivç™»å½•å¤±è´¥ï¼Œå·²å°è¯•ä¸‰æ¬¡ï¼Œè¯·å‰å¾€è®¾ç½®æ£€æŸ¥åˆ·æ–°ä»¤ç‰Œï¼Œå¹¶å°è¯•é‡æ–°ç™»å½•")


def pipeline_start_plora(ch_names):
    return pipeline_start(ch_names, 0)


def pipeline_start_lora(ch_names, toml_index):
    return pipeline_start(ch_names, 1, toml_index)


def pipeline_start(ch_names, train_type, toml_index=None):
    global output_cache
    global cfg
    bs = 4
    epoc = 10
    is_kohya = bool(train_type)
    riyu = kakasi()
    actions = [NoMonochromeAction(), CCIPAction(), PersonSplitAction(),  # ccipè§’è‰²èšç±»
               HeadCountAction(1), TaggingAction(force=True),
               FilterSimilarAction('all'), ModeConvertAction('RGB'),  # FilterSimilar: lpipså·®åˆ†è¿‡æ»¤
               FileExtAction(ext='.png'),  # pngæ ¼å¼è´¨é‡æ— æŸ
               FirstNSelectAction(1000)]  # 700+
    ch_list = ch_names.split(',')
    for ch in ch_list:
        gr.Info(f"[{ch}]"+" å…¨è‡ªåŠ¨è®­ç»ƒå¼€å§‹")
        ch = ch.replace(' ', '_')
        ch_e = ''.join([r['hepburn']for r in riyu.convert(re.sub(r'[^\w\s()]', '', ''.join([word if not (u'\u4e00' <= word <= u'\u9fff') else lazy_pinyin(ch)[i] for i, word in enumerate(ch)])))]).replace(' ', '_')
        if not is_kohya:
            save_path = f"pipeline\\dataset\\{ch_e}"
        else:
            save_path = f"pipeline\\dataset\\_kohya\\{ch_e}\\1_{ch_e}"
###
        source_init = GcharAutoSource(ch, pixiv_refresh_token=cfg.get('pixiv_token', ''))
        source_init.attach(*actions).export(
            TextualInversionExporter(save_path)
        )
###
        if not is_kohya:
            run_train_plora(ch_e, bs=bs, epoc=epoc, min_step=2000, is_pipeline=True)  # bs, epoch 32 25
        else:
            run_train_lora(ch_e, bs=bs, epoch=epoc, toml_index=toml_index, is_pipeline=True)
###

        def huggingface(workdir: str, repository, revision, n_repeats, pretrained_model,
                        width, height, clip_skip, infer_steps):
            logging.try_init_root(logging.INFO)
            deploy_to_huggingface(
                workdir, repository, revision, n_repeats, pretrained_model,
                clip_skip, width, height, infer_steps, ds_dir=save_path, is_kohya=is_kohya
            )

        def rehf(repository, revision, n_repeats, pretrained_model,
                 width, height, clip_skip, infer_steps):
            from pathlib import Path
            logging.try_init_root(logging.INFO)
            with TemporaryDirectory() as workdir:
                logging.info(f'Downloading models for {workdir!r} ...')
                hf_fs = cyber_get_hf_fs()
                for f in tqdm(hf_fs.glob(f'{repository}/*/raw/*')):
                    rel_file = Path(os.path.relpath(f, repository)).as_posix()
                    local_file = os.path.join(workdir, 'ckpts', os.path.basename(rel_file))
                    if os.path.dirname(local_file):
                        os.makedirs(os.path.dirname(local_file), exist_ok=True)
                    cyber_download_file(
                        hf_hub_url(repository, filename=rel_file),
                        local_file
                    )

                logging.info(f'Regenerating tags for {workdir!r} ...')
                pt_name, _ = find_steps_in_workdir(workdir)
                game_name = pt_name.split('_')[-1]
                name = '_'.join(pt_name.split('_')[:-1])

                from gchar.games.dispatch.access import GAME_CHARS
                if game_name in GAME_CHARS:
                    ch_cls = GAME_CHARS[game_name]
                    ch = ch_cls.get(name)
                else:
                    ch = None

                if ch is None:
                    source = repository
                else:
                    source = ch

                logging.info(f'Regenerate tags for {source!r}, on {workdir!r}.')
                save_recommended_tags(source, name=pt_name, workdir=workdir)
                logging.info('Success!')

                deploy_to_huggingface(
                    workdir, repository, revision, n_repeats, pretrained_model,
                    clip_skip, width, height, infer_steps,
                )

        def civitai(repository, title, steps, epochs, draft, publish_time, allow_nsfw,
                    version_name, force_create, no_ccip_check, session, is_pipeline=False, is_kohya=False, verify=True):
            logging.try_init_root(logging.INFO)
            model_id = civitai_publish_from_hf(
                repository, title,
                step=steps, epoch=epochs, draft=draft,
                publish_at=publish_time, allow_nsfw_images=allow_nsfw,
                version_name=version_name, force_create_model=force_create,
                no_ccip_check=no_ccip_check, session=session, is_pipeline=is_pipeline,
                is_kohya=is_kohya, toml_index=toml_index, verify=verify,
            )
            url = f'https://civitai.com/models/{model_id}'
            if not draft:
                logging.info(f'Deploy success, model now can be seen at {url} .')
            else:
                logging.info(f'Draft created, it can be seed at {url} .')

        try:
            huggingface(workdir='pipeline/runs/' + ('_kohya/' if is_kohya else '') + ch_e, repository=None, n_repeats=3, pretrained_model=_DEFAULT_INFER_MODEL, width=512, height=768, clip_skip=2, infer_steps=30, revision='main')
        except Exception as e:
            logger.error(" - é”™è¯¯:", e)
            raise e
        # if not is_kohya:
        #     try:
        #         rehf(repository=f'AppleHarem/{ch_e}', n_repeats=3, pretrained_model='_DEFAULT_INFER_MODEL', width=512, height=768, clip_skip=2, infer_steps=30, revision='main')
        #     except Exception as e:
        #         logger.error(" - é”™è¯¯:", e)
        #         raise e
        try:
            civitai(repository=f'AppleHarem/{ch_e}', draft=False, allow_nsfw=True, force_create=False, no_ccip_check=False, session=None, epochs=epoc, publish_time=None, steps=None, title=f'{ch}/{ch_e}', version_name=None, is_pipeline=True, is_kohya=is_kohya, verify=cfg.get('verify_enabled', True))
        except Exception as e:
            logger.error(" - é”™è¯¯:", e)
            raise e
        gr.Info(f"[{ch}]" + " å…¨è‡ªåŠ¨è®­ç»ƒå®Œæˆ")
        logger.success(" - å®Œæˆ: å·²å®Œæˆ"+ch+"è§’è‰²ä¸Šä¼ ")
    gr.Info("æ‰€æœ‰å…¨è‡ªåŠ¨è®­ç»ƒä»»åŠ¡å®Œæˆ")
    subprocess.call(["shutdown", "/s", "/t", "0"])  # TODO è‡ªåŠ¨å…³æœºåŠŸèƒ½
    return get_output_status(output_cache)+"æ‰€æœ‰ä»»åŠ¡å®Œæˆ"


def get_hf_token():
    return os.environ.get('HF_TOKEN')


def auto_crawler(chars_list, number):
    global crawler_clients
    crawler_clients["client_" + str(number)] = Client(f"AppleHarem/AppleBlock-{number}", hf_token=get_hf_token())
    logger.info(f"[ä¿¡æ¯] - åˆ›å»ºğŸ{number}")
    crawler_clients["client_" + str(number)] = crawler_clients["client_" + str(number)].submit(get_hf_token(), chars_list, True, api_name="/crawlup")
    logger.info(f"[ä¿¡æ¯] - æäº¤ğŸ{number}è®­ç»ƒé›†ä»»åŠ¡")
    gr.Info("[ğŸ"+str(number)+"] å…¨è‡ªåŠ¨è®­ç»ƒé›†ä»»åŠ¡å·²æäº¤")


def auto_crawler_status(number):
    global crawler_clients
    if 'crawler_clients' in globals():
        client = crawler_clients.get("client_" + str(number))
        if client is not None:
            gr.Info(str(client.status()))
            logger.debug(str(client.status()))
            logger.debug(str(client.result()))
        else:
            gr.Warning("ğŸ"+str(number) + "å°šæœªéƒ¨ç½²")
    else:
        gr.Warning("æœªéƒ¨ç½²ä»»ä½•ğŸ")


def auto_crawler_done(msg):
    logger.success(msg)
    gr.Info(msg)


def mirror_process():
    img_count = 0
    tag_count = 0
    gr.Info("é€‰æ‹©åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹")
    root = tk.Tk()
    root.withdraw()
    pths = []
    while True:
        pth = filedialog.askdirectory()
        if pth:
            pths.append(os.path.abspath(pth))
        else:
            break
    gr.Info("å¿«é€Ÿé•œåƒå¼€å§‹å¤„ç†")
    for i_pth in pths:
        output_folder = i_pth + '_mirror'
        os.makedirs(output_folder, exist_ok=False)
        for filename in tqdm(os.listdir(i_pth), file=sys.stdout, desc=" - å¿«é€Ÿé•œåƒå¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
            if filename.endswith(".jpg") or filename.endswith(".png") or filename.endswith(".jpeg"):
                img_path = os.path.join(i_pth, filename)
                txt_file = os.path.splitext(img_path)[0] + ".txt"
                json_file = os.path.splitext(img_path)[0] + ".json"
                img = cv2.imread(img_path)
                img_mirror = cv2.flip(img, 1)
                cv2.imwrite(os.path.join(output_folder, filename), img_mirror)
                img_count = img_count + 1
                # tag
                if os.path.isfile(txt_file):
                    shutil.copy(txt_file, os.path.join(output_folder, os.path.basename(txt_file)))
                    tag_count = tag_count + 1
                if os.path.isfile(json_file):
                    shutil.copy(json_file, os.path.join(output_folder, os.path.basename(json_file)))
                    tag_count = tag_count + 1
    logger.success("å¿«é€Ÿé•œåƒå¤„ç†å®Œæˆï¼Œè¾“å‡ºä½ç½®ä¸æºæ–‡ä»¶å¤¹ä½ç½®ç›¸åŒ")
    gr.Info("å¿«é€Ÿé•œåƒå¤„ç†å®Œæˆ")
    return get_output_status(output_cache)+"å¤„ç†å®Œæ¯•, å…±å¤„ç†" + str(img_count) + "å¼ å›¾ç‰‡, " + str(tag_count) + "ä¸ªtagæ–‡ä»¶"


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", type=str, default="127.0.0.1")
    parser.add_argument("--port", type=int, default=7862)
    parser.add_argument("--share", type=bool, default=False)
    args = parser.parse_args()

    matplotlib.use('Agg')
    # è¯»å–é…ç½®æ–‡ä»¶
    global cfg
    load_settings()
    output_cache = []
    # cfg = {}
    # ç™»å½•pixiv
    global pyapi
    pixiv_login()
    crawler_clients = {}
    # ç™»å½•huggingface
    # hf_login(token=os.environ.get('HF_TOKEN'))
    # ä¸»ç•Œé¢
    with gr.Blocks(css=load_css(), analytics_enabled=False) as iblock:
        quicksettings = gr.Row(elem_id="quicksettings")
        with quicksettings:
            dataset_dropdown = gr.Dropdown(ref_datasets(True), label="å½“å‰æ•°æ®é›†", value=ref_datasets(True)[0], container=True, show_label=True, interactive=True, elem_id='dataset_dropbar')
            ref_datasets_button = gr.Button("ğŸ”„", elem_id='refresh_datasets')
            reps = ref_kohya_rep(dataset_dropdown.value, True)
            kohya_rep_dropdown = gr.Dropdown(reps, label="å½“å‰å¾ªç¯", value=reps[0] if reps else [], visible=False, elem_id='rep_dropbar', interactive=True, filterable=False)
            ref_rep_button = gr.Button("ğŸ”„", elem_id='refresh_reps', visible=False, interactive=True)
            dataset_dropdown.select(kohya_rep_ctrl, None, [kohya_rep_dropdown, ref_rep_button])
        with gr.Tab("æ•°æ®è·å–"):
            with gr.Tab("å›¾ç«™"):
                source = gr.Radio(['Gelbooru', 'Pixiv', 'Zerochan', 'è‡ªåŠ¨'], label='é€‰æ‹©å›¾ç«™', value='Gelbooru')
                char_name = gr.Textbox(label='è§’è‰²åç§°', value='', placeholder='å¡«å…¥è§’è‰²å')
                pre_min_size = gr.Textbox(label="æœ€å¤§å°ºå¯¸", value="", placeholder="ä¸å¡«å†™å°†ä¸ç”Ÿæ•ˆ", interactive=True)
                pre_background = gr.ColorPicker(label="èƒŒæ™¯è‰²", value="#FFFFFF", interactive=True)
                pre_class = gr.CheckboxGroup(["ç´ æ", "3D"], label="é£æ ¼è¿‡æ»¤", value=None, type="index", interactive=True)
                pre_rating = gr.CheckboxGroup(["å¥å…¨", "r15", "r18"], label="è¯„çº§ç­›é€‰", value=["å¥å…¨"], type="index", interactive=True)
                pre_crop_person = gr.Checkbox(label="è£å‰ªäººç‰©", value=False, interactive=True)
                pre_ccip_option = gr.Checkbox(label="ç‰¹å¾åŒ¹é…", value=False, interactive=True)
                pre_auto_tagging = gr.Checkbox(label="è‡ªåŠ¨æ‰“æ ‡", value=False, interactive=True)
                with gr.Column(visible=False) as pixiv_settings:
                    pixiv_no_ai = gr.Checkbox(label="éAIç”Ÿæˆ", interactive=True, value=False)
                source.select(pixiv_setting_ctrl, None, [pixiv_settings])
                dl_count = gr.Textbox(label="ä¸‹è½½æ•°é‡", value='100', placeholder="æ— ä¸Šé™")
                # dl_count = gr.Slider(1, 1001, step=1, value=10, label="ä¸‹è½½æ•°é‡", elem_id='dl_count')
                # save_path = gr.Textbox(label='ä¿å­˜è·¯å¾„', value='dataset', placeholder='è‡ªåŠ¨åˆ›å»ºå­æ–‡ä»¶å¤¹')
                download_button = gr.Button("è·å–å›¾ç‰‡", variant="primary", interactive=True)
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""å¯¹äºå•å›¾ç«™ï¼Œå¡«å…¥è¦æœç´¢çš„ä»»ä½•å†…å®¹ä»¥è·å–å¯¹åº”æ ‡ç­¾å›¾ç‰‡\n
                                å¯¹äºè‡ªåŠ¨å›¾ç«™æºï¼Œå¿…é¡»å¡«å…¥ä¸€ä¸ªè§’è‰²å\n
                                æ‰€æœ‰å›¾ç«™æ”¯æŒå¤šå†…å®¹é¡ºåºçˆ¬å–ï¼Œç”¨åŠè§’é€—å·åˆ†éš”ï¼Œå¦‚\"é“ƒå…°,é¦™é£æ™ºä¹ƒ\"\n
                                ä¿å­˜çš„å›¾ç‰‡ä¼šä»¥æœç´¢å†…å®¹è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæ•°æ®é›†ï¼Œè·å–å®Œæˆååˆ·æ–°æ•°æ®é›†å³å¯æŸ¥çœ‹\n
                                Pixivæºé€Ÿåº¦æœ€æ…¢ã€ä¸”è´¨é‡æœ€å·®""")
                pre_rating.change(pre_rating_limit, [pre_rating], [download_button])
            with gr.Tab("ç”»å¸ˆ"):
                illu_name = gr.Textbox(label="ç”»å¸ˆå", placeholder="å®Œæ•´ç”»å¸ˆå")
                with gr.Row():
                    # illu_get_pixiv = gr.Checkbox(label="Pixiv", value=True, interactive=True)
                    # illu_get_fanbox = gr.Checkbox(label="Fanbox", value=False, interactive=True)
                    illu_get_source = gr.CheckboxGroup(["Pixiv", "Fanbox"], label="è·å–æ¸ é“", value=["Pixiv"], type="index", interactive=True)
                    illu_max_size = gr.Textbox(label="æœ€å¤§æ–‡ä»¶å¤§å°", info="MB", placeholder="ä¸å¡«å†™åˆ™æ— é™åˆ¶", value="16")
                illu_button = gr.Button("è·å–ä½œå“", variant="primary")
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""ä»…æ”¯æŒpixiv fanbox ç›®å‰\n
                                å…³äºå®Œæ•´ç”»å¸ˆåï¼šè¦å†™ç”»å¸ˆåœ¨pixivå¯¹åº”çš„åå­—ï¼Œä¸å¯ä»¥å†™fanboxä¸Šçš„è‹±æ–‡å""")
                illu_get_source.change(illu_source_limit, [illu_get_source], [illu_button])
                illu_getter_pic = gr.Image(type="filepath", label="åˆ°åº•æ˜¯å“ªä¸ªç”»å¸ˆ?")
                # illu_getter_button = gr.Button("è·å–ç”»å¸ˆå", interactive=True)
                # illu_id_tmp = gr.Textbox(visible=False)
            # with gr.Tab("å¿«é€Ÿè·å–"):
            #     fast_tag = gr.Textbox(label="Tag", placeholder="aaa,bbb|ccc,ddd", value='')
            #     fast_button = gr.Button("å¼€å§‹è·å–", variant="primary", interactive=True)
        with gr.Tab("æ•°æ®å¢å¼º"):
            with gr.Tab("å¿«é€Ÿæ“ä½œ"):
                with gr.Accordion("ä¸‰é˜¶åˆ†å‰²"):
                    stage_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                with gr.Accordion("è‡ªé€‚åº”å‰ªè£"):
                    crop_trans_thre = gr.Slider(0.01, 1, label="å®¹å·®é˜ˆå€¼", value=0.7, step=0.01)
                    crop_trans_filter = gr.Slider(0, 10, label="ç¾½åŒ–", value=5, step=1)
                    crop_trans_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""å°†æ•°æ®é›†ä¸­çš„é€æ˜å›¾ç‰‡è¿›è¡Œè‡ªé€‚åº”å‰ªè£ã€‚\n
                                    å¯å¯¹ç¼“å­˜æˆ–æ•°æ®é›†è¿›è¡Œæ“ä½œã€‚""")
                with gr.Accordion("å·®åˆ†è¿‡æ»¤"):
                    cluster_threshold = gr.Slider(0, 1, label="é˜ˆå€¼", step=0.1, value=0.45, interactive=True)
                    cluster_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""å·®åˆ†æ£€æµ‹ï¼šLPIPSï¼ˆæ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼‰ ï¼Œå…¨ç§°ä¸ºLearned Perceptual Image Patch 
                                    Similarityï¼Œæ˜¯ä¸€ç§ç”¨äºè¯„ä¼°å›¾åƒç›¸ä¼¼æ€§çš„åº¦é‡æ–¹æ³•ã€‚åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡æ¯”è¾ƒå›¾åƒä¹‹é—´çš„æ·±åº¦ç‰¹å¾è¯„ä¼°å®ƒä»¬çš„ç›¸ä¼¼æ€§\n 
                                    LPIPSä½¿ç”¨äº†é¢„è®­ç»ƒçš„åˆ†ç±»ç½‘ç»œï¼ˆå¦‚AlexNetæˆ–VGGï¼‰æ¥æå–å›¾åƒçš„ç‰¹å¾ã€‚ç„¶åè®¡ç®—ä¸¤ä¸ªå›¾åƒç‰¹å¾ä¹‹é—´çš„ä½™å¼¦è·ç¦»ï¼Œ
                                    å¹¶å¯¹æ‰€æœ‰å±‚å’Œç©ºé—´ç»´åº¦çš„è·ç¦»è¿›è¡Œå¹³å‡ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªå€¼ï¼Œç”¨äºè¡¨ç¤ºä¸¤ä¸ªå›¾åƒä¹‹é—´çš„æ„ŸçŸ¥å·®å¼‚ã€‚\n
                                    *ä¼šæš‚å­˜å»é™¤å·®åˆ†åçš„å›¾ç‰‡ç»“æœ
                                    ![cluster](resource/lpips_full.plot.py.svg)""")
                with gr.Accordion("äººç‰©åˆ†ç¦»"):
                    seg_scale = gr.Slider(32, 2048, label="ç¼©æ”¾å¤§å°", info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸", step=32, value=1024, interactive=True)
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""äººç‰©åˆ†ç¦»\n
                                    *ä¼šæš‚å­˜èƒŒæ™¯ä¸ºé€æ˜çš„äººç‰©å›¾ç‰‡ç»“æœ\n
                                    æŸ¥é˜…skytntçš„[å¤æ‚åŠ¨æ¼«æŠ åƒ](https://github.com/SkyTNT/anime-segmentation/)""")
                    seg_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                with gr.Accordion("å¿«é€Ÿæ“ä½œè¯´æ˜", open=False):
                    gr.Markdown("""å…³äºå¿«é€Ÿæ“ä½œ\n"
                                å°è‹¹æœWebUIçš„è®¾è®¡ç†å¿µæ˜¯ä¸€ä¸ªè®­ç»ƒå·¥å…·ç®±ï¼Œç”¨äºæ‰§è¡Œè½»é‡æ•°æ®é›†çš„è½»é‡æ“ä½œï¼Œä¸æ”¯æŒè¿‡å¤§æ•°æ®é›†ä¸éƒ¨åˆ†æé™ä»»åŠ¡\n
                                éƒ¨åˆ†å¿«é€Ÿæ“ä½œçš„ç»“æœå°†æš‚å­˜åˆ°å†…å­˜ä¸­ï¼Œéƒ¨åˆ†è¾“å…¥ä¹Ÿä¼šä»å†…å­˜ç»“æœä¸­è¯»å–ï¼Œè€Œä¸æ˜¯ä»æºæ•°æ®é›†ä¸­è¯»å–\n
                                è¿™ä½¿ä½ å¯ä»¥åœ¨UIä¸­é€‰æ‹©è‡ªå·±éœ€è¦çš„å·¥ä½œæµç¨‹""")
                    # TODO æœªæ¥å°†æ”¯æŒè¾“å…¥è¾“å‡ºç«¯ç‚¹å¯è§†åŒ–
            with gr.Tab("åŒºåŸŸæ£€æµ‹"):
                # with gr.Accordion("äººç‰©æ£€æµ‹"):
                #     ccip_level = gr.Checkbox(label="ä½¿ç”¨é«˜ç²¾åº¦", value=True, interactive=True)
                #     ccip_model = gr.Dropdown(["v0", "v1", "v1.1"], label="æ¨¡å‹é€‰æ‹©", value="v1.1", interactive=True)
                #     ccip_infer = gr.Slider(32, 2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
                #     ccip_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step=0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
                #     ccip_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
                #     ccip_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
                #     with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                #         gr.Markdown("è§’è‰²æ£€æµ‹ï¼šCCIPï¼ˆå¯¹æ¯”è§’è‰²å›¾åƒé¢„è®­ç»ƒï¼‰ä»åŠ¨æ¼«è§’è‰²å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè®¡ç®—ä¸¤ä¸ªè§’è‰²ä¹‹é—´çš„è§†è§‰å·®å¼‚ï¼Œå¹¶ç¡®å®šä¸¤ä¸ªå›¾åƒæ˜¯å¦"
                #                     "æç»˜ç›¸åŒçš„è§’è‰²ã€‚![ccip](resource/ccip_full.plot.py.svg)"
                #                     "æ›´å¤šä¿¡æ¯å¯æŸ¥é˜… [CCIPå®˜æ–¹æ–‡æ¡£](https://deepghs.github.io/imgutils/main/api_doc/metrics/ccip.html).")
                with gr.Accordion("é¢éƒ¨æ£€æµ‹"):
                    faced_level = gr.Checkbox(value=True, label="ä½¿ç”¨é«˜ç²¾åº¦", interactive=True)
                    faced_model = gr.Dropdown(["v0", "v1", "v1.3", "v1.4"], label="æ¨¡å‹é€‰æ‹©", value="v1.4", interactive=True)
                    faced_infer = gr.Slider(32, 2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
                    faced_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step=0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
                    faced_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""##é¢éƒ¨æ£€æµ‹
                                    æ¥è‡ªimgutilsæ£€æµ‹æ¨¡å—
                                    ###æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ""")
                    faced_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
                with gr.Accordion("å¤´éƒ¨æ£€æµ‹"):
                    headd_level = gr.Checkbox(value=True, label="ä½¿ç”¨é«˜ç²¾åº¦", interactive=True)
                    headd_infer = gr.Slider(32, 2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
                    headd_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step=0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
                    headd_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""##å¤´éƒ¨æ£€æµ‹
                                    æ¥è‡ªimgutilsæ£€æµ‹æ¨¡å—
                                    ###æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ)""")
                    headd_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
                with gr.Accordion("æ–‡æœ¬æ£€æµ‹"):
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""æ–‡æœ¬æ£€æµ‹\n
                                    ç”¨ocrçš„æ–¹å¼æ£€æµ‹æ–‡æœ¬çš„æ¨¡å—\n
                                    æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ\n
                                    æ­¤åŠŸèƒ½ç»“æœè´¨é‡å·®ï¼Œä¸å»ºè®®ä½¿ç”¨""")
                    textd_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
                with gr.Accordion("åŒºåŸŸæ£€æµ‹è¯´æ˜", open=False):
                    gr.Markdown("""æ­¤é€‰é¡¹å¡ä¸­çš„æ“ä½œæ˜¯æ£€æµ‹æ“ä½œ\n
                                å¯æ¥å—ç»“æœä¸­çš„å›¾åƒï¼Œå°†æš‚å­˜åŒºåŸŸä¿¡æ¯\n""")
            with gr.Tab("åŒºåŸŸå¤„ç†"):
                with gr.Accordion("åŒºåŸŸå¡«å……"):
                    areaf_isRandom = gr.Checkbox(label="éšæœºé¢œè‰²", value=True, interactive=True)
                    areaf_color = gr.ColorPicker(label="è‡ªå®šä¹‰é¢œè‰²", value="#00FF00", visible=not areaf_isRandom.value)
                    areaf_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""æ¥æ”¶è¾“å‡ºåçš„ç»“æœè¿›è¡Œæ‰“ç ã€‚\n
                                    è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥å¡«å……...""")
                    areaf_isRandom.select(color_picker_ctrl, None, [areaf_color])
                with gr.Accordion("åŒºåŸŸæ¨¡ç³Š"):
                    areab_radius = gr.Slider(1, 20, label="æ¨¡ç³Šå¼ºåº¦", value=4, interactive=True, step=1)
                    areab_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""æ¥æ”¶è¾“å‡ºåçš„ç»“æœè¿›è¡Œæ‰“ç ã€‚\n
                                    è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥æ¨¡ç³Š...""")
                with gr.Accordion("åŒºåŸŸå‰ªè£"):
                    crop_hw_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""å°†è¿è¡Œç»“æœä¸­çš„åŒºåŸŸè¿›è¡Œå‰ªè£ã€‚\n
                                    è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥å‰ªè£...""")
            with gr.Tab("å¿«æ·å·¥å…·"):
                with gr.Accordion("å¿«é€Ÿé•œåƒ"):
                    mirror_pickup = gr.Button("é€‰æ‹©æ–‡ä»¶å¤¹", variant="primary")
                    with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                        gr.Markdown("""å¯é€‰æ‹©å¤šä¸ªæ–‡ä»¶å¤¹ï¼Œç›´åˆ°æ‰‹åŠ¨å–æ¶ˆ\n"
                                    "ç¨‹åºå°†è‡ªåŠ¨å¸®ä½ å¤„ç†æ‰€æœ‰å›¾åƒçš„é•œåƒæ“ä½œä»¥åŠæ ‡ç­¾æ–‡ä»¶\n""")
                    with gr.Accordion("å¿«æ·å·¥å…·è¯´æ˜", open=False):
                        gr.Markdown("""æ­¤ç±»å·¥å…·éƒ¨åˆ†æ˜¯ä¸ºkohyaè®¾è®¡çš„\n
                                    ç”±äºkohyaæ•°æ®é›†ç»“æ„ç‰¹æ®Šï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è¯»å–å’Œå¤„ç†kohyaæ•°æ®é›†çš„å†…å®¹\n
                                    æ­¤ç±»å·¥å…·å¤§éƒ¨åˆ†ä½¿ç”¨äº†osåº“ï¼Œå› æ­¤ä½ å¯ä»¥ç”¨å®ƒä»¬å¤„ç†è®¡ç®—æœºä¸Šä»»ä½•ä½ç½®çš„å†…å®¹""")
        with gr.Tab("æ‰“æ ‡å™¨"):
            taggers = ["wd14", "mldanbooru", "jsonè§£æ"]
            tagger_type = gr.Dropdown(taggers, value=taggers[0], label="æ‰“æ ‡å™¨", allow_custom_value=False, interactive=True, filterable=False)
            with gr.Column(visible=tagger_type.value == taggers[0]) as tagger_wd14_settings:
                wd14_tagger_model = gr.Dropdown(["SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT"], value="ConvNextV2", label="æ‰“æ ‡æ¨¡å‹", interactive=True, filterable=False)
                wd14_general_threshold = gr.Slider(0.01, 1, value=0.35, label="æ™®é€šæ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
                wd14_character_threshold = gr.Slider(0.01, 1, value=0.85, label="è§’è‰²æ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
                wd14_format_weight = gr.Checkbox(label="å†™å…¥æƒé‡", value=False, interactive=True)
                wd14_drop_overlap = gr.Checkbox(value=True, label="ç²¾ç¡®æ‰“æ ‡", interactive=True)
                # wd14_use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
            with gr.Column(visible=tagger_type.value == taggers[1]) as tagger_mldanbooru_settings:
                ml_use_real_name = gr.Checkbox(value=False, label="æ ‡ç­¾é‡å®šå‘", info="ç”±äºåœ¨Deepdanbooruè®­ç»ƒåï¼ŒDanbooruç½‘ç«™ä¸Šçš„è®¸å¤šæ ‡ç­¾éœ€è¦é‡å‘½åå’Œé‡å®šå‘ï¼Œå› æ­¤åœ¨æŸäº›åº”ç”¨åœºæ™¯ä¸­å¯èƒ½æœ‰å¿…è¦ä½¿ç”¨æœ€æ–°çš„æ ‡ç­¾åç§°ã€‚")
                ml_threshold = gr.Slider(0.01, 1, value=0.7, label="æ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
                ml_size = gr.Slider(32, 1024, value=448, step=32, label="ç¼©æ”¾å¤§å°", interactive=True, info="å°†ç¼©æ”¾åçš„å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„å¤§å°")
                ml_keep_ratio = gr.Checkbox(value=False, label="ä¿æŒæ¯”ä¾‹", info="ä¿æŒè®­ç»ƒé›†å›¾åƒçš„åŸå§‹æ¯”ä¾‹", interactive=True)
                ml_format_weight = gr.Checkbox(label="å†™å…¥æƒé‡", value=False, interactive=True)
                ml_drop_overlap = gr.Checkbox(value=True, label="ç²¾ç¡®æ‰“æ ‡", interactive=True)
                # ml_use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
            with gr.Column(visible=tagger_type.value == taggers[2]) as tagger_anal_settings:
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""ç”¨æ­¤è„šæœ¬è·å–çš„å›¾ç‰‡é™„æœ‰jsonæ–‡ä»¶\n
                                "ä½¿ç”¨æ­¤æ‰“æ ‡å™¨ä»¥ä»ä¸­æå–tag\n"
                                "æ­¤åŠŸèƒ½ä¸ä¼šæ£€æŸ¥å›¾ç‰‡ï¼Œè€Œæ˜¯ä»æ‰€æœ‰å¯èƒ½çš„jsonæ–‡ä»¶ä¸­æå–tag""")
                anal_del_json = gr.Checkbox(value=False, label="åˆ é™¤json", interactive=True)
            use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
            with gr.Column(visible=use_blacklist.value) as tagger_dropper_settings:
                drop_use_presets = gr.Checkbox(value=True, label="ä½¿ç”¨åœ¨çº¿é»‘åå•", info="è·å–åœ¨çº¿é»‘åå•ï¼Œæ¥è‡ªalea31435", interactive=True)
                with gr.Column(visible=not drop_use_presets.value, elem_id="drop_custom_setting") as drop_custom_setting:
                    drop_custom_list = gr.Dropdown(ref_customList(True), value=ref_customList(True)[0], label="è‡ªå®šä¹‰é»‘åå•", elem_id="custom_list", interactive=True, info="é»‘åå•è·¯å¾„cfgs/blacklist/")
                    drop_ref_button = gr.Button("ğŸ”„", elem_id='refresh_custom_list')
            op_exists_txt = gr.Dropdown(["å¤åˆ¶æ–‡ä»¶", "å¿½ç•¥æ–‡ä»¶", "è¦†ç›–æ–‡ä»¶", "é™„åŠ æ ‡ç­¾"], value="é™„åŠ æ ‡ç­¾", info="å¯¹äºå·²å­˜åœ¨æ ‡ç­¾ï¼Œæ‰“æ ‡å™¨çš„è¡Œä¸º", show_label=False, interactive=True, filterable=False)
            tagger_button = gr.Button("æ‰“æ ‡", variant="primary")
            # tagger_type.select(tagger_chooser_ctrl, None, [globals()[f'tagger_{("dropper" if tagger == "æ ‡ç­¾é»‘åå•" else tagger)}_settings'] for tagger in taggers])
            tagger_type.select(tagger_chooser_ctrl, None, [globals()[f'tagger_{("anal" if tagger == "jsonè§£æ" else tagger)}_settings'] for tagger in taggers])
            # wd14_use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
            # ml_use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
            use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
            drop_use_presets.select(custom_blacklist_ctrl, None, [drop_custom_setting])
        with gr.Tab("PLoRAè®­ç»ƒ"):
            with gr.Tab("å¿«é€Ÿè®­ç»ƒ"):
                plora_min_step = gr.Textbox(label="æœ€å°æ­¥æ•°", value='', placeholder='ä¸å¡«å†™å°†è‡ªåŠ¨è®¡ç®—')
                plora_epoch = gr.Slider(1, 100, label="Epoch", value=10)
                plora_batch_size = gr.Slider(1, 64, label="Batch Size", value=4, step=1)
                plora_train_button = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary")
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""è®­ç»ƒè¯¦ç»†è¯´æ˜..ä»€ä¹ˆçš„""")
            with gr.Tab("é«˜çº§è®­ç»ƒ"):
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("soon...")
            with gr.Tab("å…¨è‡ªåŠ¨è®­ç»ƒ") as tab_pipeline_plora:
                pipeline_text_plora = gr.Textbox(label="è§’è‰²åç§°", placeholder="ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ¨¡å‹å°±å‡ºç°åœ¨cç«™äº†ã€‹", info="è¦æ±‚è§’è‰²å ç”¨,åˆ†éš”")
                pipeline_button_plora = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨è®­ç»ƒ", variant="primary")
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ¨¡å‹å°±å‡ºç°åœ¨cç«™äº†ã€‹\n
                                éœ€è¦åœ¨è®¾ç½®ä¸­è®¾ç½®cç«™token\n
                                éœ€è¦åœ¨è®¡ç®—æœºä¸­æ·»åŠ ç¯å¢ƒå˜é‡: é”®å HF_TOKEN å€¼: ä»ç™»å½•çš„HuggingFaceç½‘ç«™è·å– åœ¨è´¦å·è®¾ç½®ä¸­åˆ›å»ºè®¿é—®ä»¤ç‰Œ""")
        toml_presets = ['é»˜è®¤', 'ä¸€æ¯å“ˆè¨å§†', 'ç¥ç€é’è‘‰']
        with gr.Tab("LoRAè®­ç»ƒ"):
            with gr.Tab("å¿«é€Ÿè®­ç»ƒ"):
                lora_epoch = gr.Slider(1, 100, label="Epoch", value=10)
                lora_batch_size = gr.Slider(1, 64, label="Batch Size", value=1, step=1)
                lora_toml_presets = gr.Radio(toml_presets, label="å‚æ•°", info="é€šç”¨åŒ–çš„å‚æ•°é¢„è®¾", type="index", value="é»˜è®¤", interactive=True)
                lora_train_button = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary")
            with gr.Tab("é«˜çº§è®­ç»ƒ"):
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("soon...")
            with gr.Tab("å…¨è‡ªåŠ¨è®­ç»ƒ") as tab_pipeline_lora:
                pipeline_text_lora = gr.Textbox(label="è§’è‰²åç§°", placeholder="ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ¨¡å‹å°±å‡ºç°åœ¨cç«™äº†ã€‹", info="è¦æ±‚è§’è‰²å ç”¨,åˆ†éš”")
                pipeline_toml_presets = gr.Radio(toml_presets, label="å‚æ•°", info="é€šç”¨åŒ–çš„å‚æ•°é¢„è®¾", type="index", value="é»˜è®¤")
                pipeline_button_lora = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨è®­ç»ƒ", variant="primary")
                with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                    gr.Markdown("""ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ¨¡å‹å°±å‡ºç°åœ¨cç«™äº†ã€‹\n
                                éœ€è¦åœ¨è®¾ç½®ä¸­è®¾ç½®cç«™token\n
                                éœ€è¦åœ¨è®¡ç®—æœºä¸­æ·»åŠ ç¯å¢ƒå˜é‡: é”®å HF_TOKEN å€¼: ä»ç™»å½•çš„HuggingFaceç½‘ç«™è·å– åœ¨è´¦å·è®¾ç½®ä¸­åˆ›å»ºè®¿é—®ä»¤ç‰Œ""")
        with gr.Tab("è´¨é‡è¯„ä¼°"):
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("soon...")
        with gr.Tab("ä¸Šä¼ æƒé‡"):
            with gr.Accordion("LoRAåˆå¹¶", open=True):
                with gr.Column(elem_id="convert_lora_steps") as convert_lora_steps:
                    convert_step = gr.Dropdown(ref_runs(dataset_dropdown.value, True), value=ref_runs(dataset_dropdown.value, True)[0] if ref_runs(dataset_dropdown.value, True) else [], label="æ­¥æ•°",
                                               info="HCPå¯ç”¨,åˆå¹¶å¯¹åº”æ­¥æ•°çš„æƒé‡æ–‡ä»¶", elem_id="convert_list", multiselect=False, interactive=True, filterable=False)
                    convert_ref_button = gr.Button("ğŸ”„", elem_id='convert_ref_button')
                convert_weights_button = gr.Button("å¼€å§‹åˆå¹¶", variant="primary")
            with gr.Accordion("æƒé‡æ‹†è§£", open=True):
                # å¤§æ¨¡å‹æƒé‡æ‹†è§£ sd 2 diffusers æ ¼å¼
                pass
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("ä¸Šä¼ æƒé‡åˆ°æŠ±è„¸å’ŒCç«™ soon..")
        with gr.Tab("å…¨è‡ªåŠ¨æ•°æ®é›†"):
            with gr.Tab("1æœº"):
                auto_crawl_1_chars = gr.Textbox(label="è§’è‰²åç§°", placeholder="ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ•°æ®é›†å°±å‡ºç°åœ¨æŠ±è„¸äº†ã€‹", info="è¦æ±‚è§’è‰²å ç”¨,åˆ†éš”")
                auto_crawl_1_button = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨æ•°æ®é›†", variant="primary")
                auto_crawl_1_status = gr.Button("æŸ¥è¯¢çŠ¶æ€")
                auto_crawl_1_number = gr.Textbox(value="1", visible=False)
            with gr.Tab("2æœº"):
                auto_crawl_2_chars = gr.Textbox(label="è§’è‰²åç§°", placeholder="ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ•°æ®é›†å°±å‡ºç°åœ¨æŠ±è„¸äº†ã€‹", info="è¦æ±‚è§’è‰²å ç”¨,åˆ†éš”")
                auto_crawl_2_button = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨æ•°æ®é›†", variant="primary")
                auto_crawl_2_status = gr.Button("æŸ¥è¯¢çŠ¶æ€")
                auto_crawl_2_number = gr.Textbox(value="2", visible=False)
            with gr.Tab("3æœº"):
                auto_crawl_3_chars = gr.Textbox(label="è§’è‰²åç§°", placeholder="ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ•°æ®é›†å°±å‡ºç°åœ¨æŠ±è„¸äº†ã€‹", info="è¦æ±‚è§’è‰²å ç”¨,åˆ†éš”")
                auto_crawl_3_button = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨æ•°æ®é›†", variant="primary")
                auto_crawl_3_status = gr.Button("æŸ¥è¯¢çŠ¶æ€")
                auto_crawl_3_number = gr.Textbox(value="3", visible=False)
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("""ã€Šè¾“å…¥è§’è‰²åç„¶åä½ çš„æ•°æ®é›†å°±å‡ºç°åœ¨æŠ±è„¸äº†ã€‹\n
                            éœ€è¦è®¾ç½®æŠ±è„¸token\n
                            ä½ å¿…é¡»æ‹¥æœ‰ç»„ç»‡çš„è¯»å†™æƒé™""")
        with gr.Tab("è®¾ç½®"):
            with gr.Tab("Pixiv"):
                pixiv_token = gr.Textbox(label="åˆ·æ–°ä»¤ç‰Œ", placeholder="ä¸å¡«å†™å°†æ— æ³•è®¿é—®Pixiv", interactive=True, value=cfg.get('pixiv_token', ''))
                pixiv_get_token = gr.Button("å‰å¾€æŸ¥è¯¢", interactive=True)
                with gr.Accordion("ä»¤ç‰Œè¯´æ˜", open=False):
                    gr.Markdown("""è·å–Pixivå›¾ç‰‡éœ€è¦åˆ·æ–°ä»¤ç‰Œ\n
                                ç”¨æ³•ï¼šç‚¹å‡»`å‰å¾€è·å–`ï¼Œå°†æ‰“å¼€Pixivç½‘é¡µï¼ŒæŒ‰F12å¯ç”¨å¼€å‘è€…æ§åˆ¶å°ï¼Œé€‰æ‹©`ç½‘ç»œ/Network`ï¼Œç‚¹å‡»å·¦ä¾§ç¬¬ä¸‰ä¸ªæŒ‰é’®`ç­›é€‰å™¨`ï¼Œ
                                ç­›é€‰`callback?`ç‚¹å‡»ç»§ç»­ä½¿ç”¨æ­¤è´¦å·ç™»å½•ï¼Œæ­¤æ—¶é¡µé¢ä¼šè·³è½¬ï¼Œå¼€å‘è€…æ§åˆ¶å°ä¼šå‡ºç°ä¸€æ¡è¯·æ±‚ï¼Œç‚¹å‡»å®ƒï¼Œè¿›å…¥`æ ‡å¤´`
                                å¤åˆ¶`code=`åçš„å†…å®¹ï¼Œå¡«å…¥åå°ï¼ˆé»‘çª—å£ï¼‰æŒ‰å›è½¦ï¼Œåå°å°†è¿”å›ä½ çš„refresh token\n
                                æ‰“å¼€webuiæ—¶ä¼šå°è¯•è‡ªåŠ¨ç™»å½•ï¼Œå¦‚æœå¤±è´¥è¯·å°è¯•ä¸‹æ–¹ç™»å½•æŒ‰é’®ï¼Œéœ€è¦å…ˆå¡«å†™åˆ·æ–°ä»¤ç‰Œå¹¶ä¿å­˜\n
                                æ§åˆ¶å°ä¸­å¯ä»¥çœ‹åˆ°ç™»å½•ä¿¡æ¯\n
                                å–æ¶ˆæŸ¥è¯¢è¯·åœ¨åå°æŒ‰ctrl+c""")
                # settings_list = [pixiv_token]
                pixiv_manual_login = gr.Button("å°è¯•ç™»å½•", interactive=True)
            with gr.Tab("Fanbox"):
                fanbox_cookie = gr.Textbox(label="Cookie", lines=13, placeholder="ä¸å¡«å†™å°†æ— æ³•è·å–Fanboxå†…å®¹", interactive=True, value=cfg.get('fanbox_cookie', ''))
                fanbox_get_cookie = gr.Button("å‰å¾€æŸ¥è¯¢", interactive=True)
                with gr.Accordion("Cookieè¯´æ˜", open=False):
                    gr.Markdown("""è·å–Fanboxå›¾ç‰‡éœ€è¦Kemonoç½‘ç«™Cookie\n
                                Cookieæ ¼å¼ï¼š[{xxx},{x..}]ï¼Œåä¸ºsessionçš„cookie\n
                                å…·ä½“æ“ä½œï¼šä½¿ç”¨EditThisCookieæµè§ˆå™¨æ‰©å±•\n
                                è¿›å…¥Kemonoç½‘ç«™ï¼Œå¯¼å‡ºcookieï¼Œå°†cookieç²˜è´´åˆ°è®¾ç½®ä¸­ï¼Œåˆ é™¤ç¬¬ä¸€é¡¹å’Œç¬¬ä¸‰é¡¹ï¼Œ\n
                                æ— éœ€[]å¤§æ‹¬å·ï¼Œåªä¿ç•™åä¸ºsessionçš„cookie{xxx}å³å¯""")
            with gr.Tab("Civitai"):
                civitai_token = gr.Textbox(label="Cookie", lines=13, placeholder="ä¸å¡«å†™æ— æ³•è‡ªåŠ¨ä¸Šä¼ cç«™", interactive=True, value=cfg.get('civitai_token', ''))
            with gr.Tab("Huggingface"):
                hf_token_show = gr.Textbox(label="Token", value=get_hf_token(), info="Huggingfaceçš„tokenéœ€è¦åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®", interactive=False)
                hf_token_ref = gr.Button("åˆ·æ–°token")
            with gr.Tab("ç½‘ç»œè®¾ç½®"):
                proxie_ip = gr.Textbox(label="ä»£ç†IPåœ°å€", placeholder="ä»£ç†è½¯ä»¶çš„IPåœ°å€", value=cfg.get('proxie_ip', ''))
                proxie_port = gr.Textbox(label="ä»£ç†ç«¯å£", placeholder="ä»£ç†è½¯ä»¶ä¸­çš„ç«¯å£", value=cfg.get('proxie_port', ''))
                proxie_enabled = gr.Checkbox(label="å¯ç”¨ä»£ç†", interactive=True, value=cfg.get('proxie_enabled', False))
                verify_enabled = gr.Checkbox(label="å¯ç”¨éªŒè¯", info="SSL/TLS è¯ä¹¦éªŒè¯", value=cfg.get('verify_enabled', True))
            with gr.Tab("ç•Œé¢è®¾ç½®"):
                theme_light = gr.Radio(['äº®è‰²', 'æš—è‰²'], label="é¢œè‰²åˆ‡æ¢", interactive=True, info="éœ€è¦é‡å¯", value='äº®è‰²' if cfg.get('theme_light', 'Light') == 'Light' else 'æš—è‰²')
                theme_style = gr.Dropdown(['é»˜è®¤', 'NovelAI', 'Soft'], label="ç•Œé¢ä¸»é¢˜", interactive=True, info="éœ€è¦é‡å¯", value='é»˜è®¤' if cfg.get('theme_style', 'Default') == 'Default' else cfg.get('theme_style', 'Default'), filterable=False)
            setting_save_button = gr.Button("ä¿å­˜", interactive=True, variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("""###æˆ‘åªæ˜¯ä¸ªæ‰“é…±æ²¹çš„...""")
        with gr.Column(elem_id="output"):
            message_output = gr.Textbox(label='è¿è¡Œç»“æœ', elem_id="message_output")
            save_output = gr.Button("ğŸ’¾", elem_id="save_output", interactive=False)
            message_output.change(save_output_ctrl, [], save_output)
        # dl_count.change(None, )
        mirror_pickup.click(mirror_process, [], [message_output])
        auto_crawl_1_button.click(auto_crawler, [auto_crawl_1_chars, auto_crawl_1_number], [])
        auto_crawl_2_button.click(auto_crawler, [auto_crawl_2_chars, auto_crawl_2_number], [])
        auto_crawl_3_button.click(auto_crawler, [auto_crawl_3_chars, auto_crawl_3_number], [])
        auto_crawl_1_status.click(auto_crawler_status, [auto_crawl_1_number], [])
        auto_crawl_2_status.click(auto_crawler_status, [auto_crawl_2_number], [])
        auto_crawl_3_status.click(auto_crawler_status, [auto_crawl_3_number], [])
        pipeline_button_plora.click(pipeline_start_plora, [pipeline_text_plora], [message_output])
        pipeline_button_lora.click(pipeline_start_lora, [pipeline_text_lora, pipeline_toml_presets], [message_output])
        setting_save_button.click(save_settings, [pixiv_token, fanbox_cookie, civitai_token, proxie_ip, proxie_port, proxie_enabled, verify_enabled, theme_light, theme_style], [message_output])
        pixiv_manual_login.click(pixiv_login, [], [])
        pixiv_get_token.click(get_ref_token, [], [])
        fanbox_get_cookie.click(get_fanbox_cookie, [], [])
        # fast_button.click(get_danbooru_fast, [fast_tag], [])
        # illu_getter_button.click(illu_getter, [illu_getter_pic], [message_output, illu_name])
        illu_getter_pic.upload(illu_getter, [illu_getter_pic], [message_output, illu_name])
        download_button.click(download_images, [source, char_name, pre_min_size, pre_background, pre_class, pre_rating, pre_crop_person, pre_ccip_option, pre_auto_tagging, dl_count, pixiv_no_ai],
                              [message_output], scroll_to_output=True)
        ref_datasets_button.click(ref_datasets, [], [dataset_dropdown])
        ref_rep_button.click(ref_kohya_rep, [dataset_dropdown], [kohya_rep_dropdown])
        stage_button.click(three_stage, [dataset_dropdown, kohya_rep_dropdown], [message_output])
        drop_ref_button.click(ref_customList, [], [drop_custom_list])
        convert_ref_button.click(ref_runs, [dataset_dropdown], [convert_step])
        convert_weights_button.click(convert_weights, [dataset_dropdown, convert_step], [message_output])
        cluster_button.click(clustering, [dataset_dropdown, cluster_threshold, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        seg_button.click(img_segment, [dataset_dropdown, seg_scale, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        # ccip_button.click(person_detect, [dataset_dropdown, ccip_level, ccip_model, ccip_infer, ccip_conf, ccip_iou], [message_output])
        faced_button.click(face_detect, [dataset_dropdown, faced_level, faced_model, faced_infer, faced_conf, faced_iou, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        headd_button.click(head_detect, [dataset_dropdown, headd_level, headd_infer, headd_conf, headd_iou, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        textd_button.click(text_detect, [dataset_dropdown, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        plora_train_button.click(run_train_plora, [dataset_dropdown, plora_min_step, plora_batch_size, plora_epoch], [message_output], scroll_to_output=True)
        lora_train_button.click(run_train_lora, [dataset_dropdown, lora_epoch, lora_batch_size, lora_toml_presets], [message_output], scroll_to_output=True)
        areaf_button.click(area_fill, [dataset_dropdown, areaf_isRandom, areaf_color, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        areab_button.click(area_blur, [dataset_dropdown, areab_radius, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        crop_hw_button.click(crop_hw, [dataset_dropdown, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        crop_trans_button.click(crop_trans, [dataset_dropdown, crop_trans_thre, crop_trans_filter, kohya_rep_dropdown], [message_output], scroll_to_output=True)
        tagger_button.click(tagging_main,
                            [dataset_dropdown, tagger_type, wd14_tagger_model, wd14_general_threshold, wd14_character_threshold, wd14_format_weight, wd14_drop_overlap, ml_use_real_name, ml_threshold,
                             ml_size, ml_format_weight, ml_keep_ratio, ml_drop_overlap, use_blacklist, drop_use_presets, drop_custom_list, op_exists_txt, anal_del_json, kohya_rep_dropdown], [message_output],
                            scroll_to_output=True)
        illu_button.click(download_illust, [illu_name, illu_get_source, illu_max_size], [message_output], scroll_to_output=True)
        save_output.click(saving_output, [dataset_dropdown], [message_output])
        iblock.title = "å°è‹¹æœwebui"

    # log.info(f"Server started at http://{args.host}:{args.port}")
    if sys.platform == "win32":
        webbrowser.open(f"http://{args.host}:{args.port}" + ("?__theme=dark" if cfg.get('theme_light', 'Light') == 'Dark' else ""))
    iblock.queue()
    iblock.launch(server_port=args.port, server_name=args.host, share=args.share)
