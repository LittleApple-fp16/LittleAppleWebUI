import io
import logging
import sys
import time

import matplotlib
import os
import gradio as gr
import random
import json
import glob
import numpy
import argparse
import webbrowser
from littleapple.refresh_token import get_ref_token
from littleapple.image_link import get_image_links, download_link
from littleapple.kemono_dl.main import downloader as kemono_dl
from littleapple.kemono_dl.args import get_args as kemono_args
from typing import Literal, cast
from pixivpy3 import AppPixivAPI, PixivError
from tqdm import tqdm
from tqdm.contrib import tzip
from waifuc.action import HeadCountAction, AlignMinSizeAction, CCIPAction, ThreeStageSplitAction, ModeConvertAction, ClassFilterAction, PersonSplitAction, TaggingAction, RatingFilterAction, NoMonochromeAction, RandomFilenameAction
from waifuc.export import SaveExporter, TextualInversionExporter
from waifuc.source import DanbooruSource, PixivSearchSource, ZerochanSource, LocalSource, GcharAutoSource
from PIL import Image
from train import run_train_plora
from imgutils.data import load_image, load_images, rgb_encode, rgb_decode
from imgutils.tagging import get_wd14_tags, get_mldanbooru_tags, drop_blacklisted_tags, drop_overlap_tags, tags_to_text
from imgutils.metrics import ccip_difference, ccip_clustering, lpips_clustering
from imgutils.operate import censor_areas, squeeze, squeeze_with_transparency
from imgutils.detect import detect_faces, detect_heads, detection_visualize, detect_person
from imgutils.segment import segment_rgba_with_isnetis
from imgutils.ocr import detect_text_with_ocr
from cyberharem.publish.convert import convert_to_webui_lora

matplotlib.use('Agg')


def download_images(source_type, character_name, p_min_size, p_background, p_class, p_rating, p_crop_person, p_auto_tagging, num_images, p_ai):
    global output_cache
    actions = []
    rating_map = {0: 'safe', 1: 'r15', 2: 'r18'}
    class_map = {1: 'illustration', 2: 'bangumi'}
    ratings_to_filter = set(rating_map.values()) - set([rating_map[i] for i in p_rating if i in rating_map])
    # ratings_to_filter = set([rating_map[i] for i in p_rating if i in rating_map])
    print("\n - å¼€å§‹è·å–æ•°æ®é›†")
    character_list = character_name.split(',')
    for character in character_list:
        character = character.replace(' ', '_')  # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        save_path = 'dataset/' + character
        if source_type == 'Danbooru':
            source_init = DanbooruSource([character, 'solo'])
        elif source_type == 'Pixiv':
            if not cfg.get('pixiv_token', ''):
                return "Pixivè®¿é—®ä»¤ç‰Œæœªè®¾ç½®"
            source_init = PixivSearchSource(
                character,
                no_ai=p_ai,
                refresh_token=cfg.get('pixiv_token', '')
            )
            actions.append(CCIPAction())  # ç”¨äºè¿‡æ»¤pixivä¼ å›çš„ä¸ç›¸å…³è§’è‰²å›¾åƒ
        elif source_type == 'Zerochan':
            source_init = ZerochanSource([character, 'solo'])
        elif source_type == 'è‡ªåŠ¨':
            source_init = GcharAutoSource(character, pixiv_refresh_token=cfg.get('pixiv_token', ''))
            actions.append(CCIPAction())
        else:
            output_cache = []
            return "å›¾ç«™é”™è¯¯"
        if p_class:
            if 0 in p_class:
                actions.append(NoMonochromeAction())
            # class_to_filter = set(class_map.values()) - set([class_map[i] for i in p_class if i in class_map])
            class_to_filter = set([class_map[i] for i in p_class if i in class_map])
            actions.append(ClassFilterAction(cast(list[Literal['illustration', 2: 'bangumi']], list(class_to_filter))))  # è¿‡æ»¤å…·æœ‰è¯„çº§çš„å›¾ç‰‡
        if p_crop_person:
            actions.append(PersonSplitAction())
        if p_auto_tagging:
            actions.append(TaggingAction(force=True))
        if p_min_size:
            # print(int(p_min_size))
            actions.append(AlignMinSizeAction(min_size=int(p_min_size)))
        actions.append(ModeConvertAction('RGB', p_background))
        actions.append(HeadCountAction(1))
        actions.append(RandomFilenameAction(ext='.png'))
        # print(cast(list[Literal['safe', 'r15', 'r18']], list(ratings_to_filter)))
        actions.append(RatingFilterAction(ratings=cast(list[Literal['safe', 'r15', 'r18']], list(ratings_to_filter))))
        source_init.attach(*actions)[:int(num_images)].export(  # åªä¸‹è½½å‰num_imageså¼ å›¾ç‰‡
            TextualInversionExporter(save_path)  # å°†å›¾ç‰‡ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
        )
        # print(ratings_to_filter)
    output_cache = []
    return "å·²è·å–å›¾ç‰‡"


def dataset_getImg(dataset_name):  # è¯·ç¡®ä¿æ¯ä¸ªæ–¹æ³•ä¸­åªè°ƒç”¨ä¸€æ¬¡ ç”±äºtqdm
    global output_cache
    print(" - åŠ è½½æ•°æ®é›†å›¾åƒ...")
    dataset_path = "dataset/" + dataset_name
    images = []
    img_name = []
    for filename in os.listdir(dataset_path):
        if filename.endswith(('.png', '.jpg', '.jpeg')):
            img = Image.open(os.path.join(dataset_path, filename))
            if img is not None:
                images.append(img)
                img_name.append(filename)
    # output_cache = images
    images = load_images(images)
    return images, img_name


def download_illust(i_name, i_source):
    # get_image_links()
    global pyapi
    try:
        json_result = pyapi.search_user(i_name)
        # print(json_result)
        illust = json_result.user_previews[0].illusts[0]
        # print(illust)
        links = get_image_links(illust['user']['id'])
        # print(links)
        kemono_arg = kemono_args()
    #     cookies = {
    #     "domain": "kemono.su",
    #     "expirationDate": "12345.67",
    #     "hostOnly": "true",
    #     "httpOnly": "true",
    #     "name": "session",
    #     "path": "/",
    #     "sameSite": "unspecified",
    #     "secure": "false",
    #     "session": "false",
    #     "storeId": "0",
    #     "value": "xxx",
    #     "id": "2"
    # }
    #     with open("cfgs/kemono_cookie.txt", "r") as f:
    #         cookies = json.load(f)
    #     kemono_arg["dirname_pattern"] = 'dataset\i_name\{service}\{username} [{user_id}]',
        kemono_arg["cookies"] = {k: str(v) for k, v in json.loads(cfg['fanbox_cookie']).items()}
        # print(kemono_arg["cookies"])
        kemono_arg["links"] = ["https://kemono.su/fanbox/user/" + str(illust['user']['id'])]
        kemono_arg["dirname_pattern"] = f"dataset/{i_name}"
        # print(i_source)
        if 0 in i_source:
            for url, name in tzip(links[0], links[1], file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ•°æ®é›†è·å–å¼€å§‹å¤„ç†"):
                if not os.path.exists(f"dataset/{illust['user']['name']}"):
                    os.makedirs(f"dataset/{illust['user']['name']}")
                download_link(url, f"dataset/{illust['user']['name']}/{name}.png")
        # print(">>> %s, origin url: %s" % (illust.title, illust.image_urls['large']))
        # return "å·²è·å–"+illust['user']['name']+"ç”»å¸ˆæ•°æ®é›†"
        if 1 in i_source:
            kemono_dl(kemono_arg)
    except:
        print("[é”™è¯¯] - è·å–å¤±è´¥\nä½ å¿…é¡»è®¾ç½®Pixivè®¿é—®ä»¤ç‰Œæ‰èƒ½è·å–Pixivçš„å†…å®¹\nä½ å¿…é¡»è®¾ç½®Kemonoä»¤ç‰Œæ‰èƒ½è·å–Fanboxçš„å†…å®¹\nä½ å¿…é¡»è¾“å…¥æ­£ç¡®çš„ç”»å¸ˆå")
        return "è·å–å¤±è´¥\nä½ å¿…é¡»è®¾ç½®Pixivè®¿é—®ä»¤ç‰Œæ‰èƒ½è·å–Pixivçš„å†…å®¹\nä½ å¿…é¡»è®¾ç½®Kemonoä»¤ç‰Œæ‰èƒ½è·å–Fanboxçš„å†…å®¹\nä½ å¿…é¡»è¾“å…¥æ­£ç¡®çš„ç”»å¸ˆå"


def get_fanbox_cookie():
    webbrowser.open(f"https://kemono.su/account/login")


def has_image(got_list):
    if any(isinstance(item, Image.Image) for item in got_list):
        return True
    else:
        return False


def clustering(dataset_name, thre):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    # print(clusters)
    clustered_imgs = []
    added_clusters = set()  # åˆ›å»ºä¸€ä¸ªé›†åˆ å…¶ä¸­å­˜å‚¨å·²ç»æ·»åŠ è¿‡çš„æ ‡ç­¾ æ­¤é›†åˆå°†çº¦æŸè¢«è¿‡æ»¤çš„imgåˆ—è¡¨ é›†åˆä¸­çš„å…ƒç´ æ— æ³•dup
    # print(" - å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç†")
    for i, cluster in enumerate(tqdm(lpips_clustering(images, thre), file=sys.stdout, desc=" - å·®åˆ†è¿‡æ»¤å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ")):  # èšç±»æ–¹æ³• -1è¡¨ç¤ºnoiseï¼Œä¸sklearnä¸­çš„ç›¸åŒ
        if cluster == -1:
            clustered_imgs.append(images[i])
        elif cluster not in added_clusters:
            clustered_imgs.append(images[i])
            added_clusters.add(cluster)
    output_cache = clustered_imgs
    return clustered_imgs


def three_stage(dataset_name):
    global output_cache
    if dataset_name.endswith("_processed"):
        process_dir = f"dataset/{dataset_name}"
    else:
        process_dir = f"dataset/{dataset_name}_processed"
    local_source = LocalSource(f"dataset/{dataset_name}")
    local_source.attach(
        ThreeStageSplitAction(),
    ).export(TextualInversionExporter(process_dir, True))
    output_cache = []
    return "å·²ä¿å­˜è‡³"+process_dir+"æ–‡ä»¶å¤¹"

# def person_detect(dataset_name, level, version, max_infer_size, conf_threshold, iou_threshold):
#     global output_cache
#     images = dataset_getImg(dataset_name)[0]
#     detected = []
#     if level:
#         level = "m"
#     else:
#         level = "n"
#     print(" - äººç‰©æ£€æµ‹å¼€å§‹å¤„ç†")
#     for img in tqdm(images):
#         detected.append(detect_person(img, level, version, max_infer_size, conf_threshold, iou_threshold))
#     output_cache = detected
#     return detected


def face_detect(dataset_name, level, version, max_infer_size, conf_threshold, iou_threshold):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    detected = []
    if level:
        level = "s"
    else:
        level = "n"
    # print(" - é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†")
    # print("   *å°†è¿”å›åŒºåŸŸç»“æœ")
    for img in tqdm(images, file=sys.stdout, desc=" - é¢éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        detected.append(detect_faces(img, level, version, max_infer_size, conf_threshold, iou_threshold))
    output_cache = detected
    return detected


def head_detect(dataset_name, level, max_infer_size, conf_threshold, iou_threshold):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    detected = []
    if level:
        level = "s"
    else:
        level = "n"
    # print(" - å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†")
    # print("   *å°†è¿”å›åŒºåŸŸç»“æœ")
    for img in tqdm(images, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - å¤´éƒ¨æ£€æµ‹å¼€å§‹å¤„ç†"):
        detected.append(detect_heads(img, level, max_infer_size, conf_threshold, iou_threshold))
    output_cache = detected
    return detected


def text_detect(dataset_name):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    detected = []
    for img in tqdm(images, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ–‡æœ¬æ£€æµ‹å¼€å§‹å¤„ç†"):
        detected.append(detect_text_with_ocr(img))
    output_cache = detected
    return detected


def area_fill(dataset_name, is_random, color):
    global output_cache
    area = output_cache
    images = dataset_getImg(dataset_name)[0]
    fill = []
    xyxy = []
    # print(" - åŒºåŸŸå¡«å……å¼€å§‹å¤„ç†")
    for img, xyxys in tzip(images, area, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - åŒºåŸŸå¡«å……å¼€å§‹å¤„ç†"):
        if xyxys:
            for exy in [xyxys][0]:
                xyxy.append(exy[0])
        if is_random:
            color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
            color = random.choice(color)
            # color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
        # print(img, eval(area), xyxys, xyxys[0][0])
        fill.append(censor_areas(img, 'color', xyxy, color=color))  # [xyxys[0][0]]
    # os.makedirs(f"processed/{dataset_name}", exist_ok=True)
    # for i, sv in enumerate(fill):
    #     sv.save(f"processed/{dataset_name}/{dataset_name}_AreaFill_{i+1}.png")
    output_cache = fill
    return fill


def area_blur(dataset_name, rad):
    global output_cache
    area = output_cache
    images = dataset_getImg(dataset_name)[0]
    blur = []
    xyxy = []
    for img, xyxys in tzip(images, area, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - åŒºåŸŸæ¨¡ç³Šå¼€å§‹å¤„ç†"):
        if xyxys:
            for exy in [xyxys][0]:
                xyxy.append(exy[0])
            blur.append(censor_areas(img, 'blur', xyxy, radius=rad))
        else:
            blur.append(img)
    output_cache = blur
    return blur


def crop_hw(dataset_name):
    global output_cache
    mask_info = output_cache
    images = dataset_getImg(dataset_name)[0]
    result = []
    for img, infos in zip(images, mask_info):
        # infos = infos[0]
        print(infos)
        for einfo in infos:
            (x0, y0, x1, y1) = einfo[0]
            detect_type = einfo[1]
            # score = infos[2]
            img_array = numpy.array(rgb_encode(img))
            h, w = img_array.shape[1:]
            mask = numpy.zeros((h, w))
            # print(mask, h, w)
            if detect_type == 'face' or detect_type == 'head' or detect_type == 'text':
                mask[y0:y1, x0:x1] = 1
                # print(mask)
            else:
                output_cache = []
                return "æ­¤å†…å®¹ä¸æ”¯æŒå‰ªè£"
            result.append(squeeze(img, mask))
    output_cache = result
    return result


def crop_trans(dataset_name, threshold, filter_size):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    out = []
    # print(" - è‡ªé€‚åº”è£å‰ªå¼€å§‹å¤„ç†")
    for img in tqdm(images, file=sys.stdout, desc=" - è‡ªé€‚åº”è£å‰ªå¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        if img is not None:
            out.append(squeeze_with_transparency(img, threshold, filter_size))
    output_cache = out
    return out


def img_segment(dataset_name, scale):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    out = []
    # print(" - äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç†")
    for img in tqdm(images, file=sys.stdout, desc=" - äººç‰©åˆ†ç¦»å¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
        out.append(segment_rgba_with_isnetis(img, scale)[1])  # maskä¿¡æ¯è¢«ä¸¢å¼ƒäº†
    output_cache = out
    return out


def ref_datasets(need_list=False):
    # éå†æœ¬åœ°æ•°æ®é›†
    list_datasets = []
    with os.scandir("dataset") as datasets:
        for each_dataset in datasets:
            # f_dataset = each_dataset.__next__()
            if not each_dataset.name.startswith('.') and each_dataset.is_dir():
                list_datasets.append(each_dataset.name)
    if need_list:
        return list_datasets
    else:
        return gr.Dropdown.update(choices=list_datasets)


def ref_customList(need_list=False):
    custom_blacklist = []
    with os.scandir("cfgs/blacklist") as blacklists:
        for each_black in blacklists:
            if not each_black.name.startswith('.') and each_black.is_file():
                if each_black.name.endswith('.txt') or each_black.name.endswith('.json'):
                    custom_blacklist.append(each_black.name)
    if need_list:
        return custom_blacklist
    else:
        return gr.Dropdown.update(choices=custom_blacklist)


def ref_runs(dataset_name, need_list=False):
    runs_list = []
    try:
        with os.scandir(f"runs/{dataset_name}/ckpts") as conv_list:
            for conv in conv_list:
                # print("éå†äº†ä¸€ä¸ªconv")
                if conv.is_file():
                    if conv.name.endswith('.pt'):
                        runs_list.append(conv.name.replace(dataset_name+"-", "").replace(".pt", ""))
    except FileNotFoundError:
        if need_list:
            return []
        else:
            return gr.Dropdown.update(choices=[])
    if runs_list is not None:
        runs_list = sorted(runs_list, key=int, reverse=True)
        if need_list:
            return runs_list
        else:
            # print("ç»“æœ"+str(runs_list))
            return gr.Dropdown.update(choices=runs_list)


def convert_weights(dataset_name, step):
    global output_cache
    # logging.try_init_root(logging.INFO)
    convert_to_webui_lora(f"runs/{dataset_name}/ckpts/unet-{step}.safetensors",
                          f"runs/{dataset_name}/ckpts/text_encoder-{step}.safetensors",
                          os.path.join(f"runs/{dataset_name}/ckpts", f"{dataset_name}-lora-{step}.safetensors")
                          )
    output_cache = []
    return "å·²æ‰§è¡Œè½¬æ¢"


def tagger_chooser_ctrl(evt: gr.SelectData):  # æ­¤æ–¹æ³•ä½¿ç”¨å…¨å±€å˜é‡
    # print(evt.value+"æ­£åœ¨é€‰æ‹©")
    # éšè—æ‰€æœ‰æ‰“æ ‡å™¨è®¾ç½®
    updates = {}
    for tagger in taggers:
        # if tagger == "æ ‡ç­¾é»‘åå•":
        #     tagger = "dropper"
        if tagger == "jsonè§£æ":
            tagger = "anal"
        updates[globals()[f"tagger_{tagger}_settings"]] = gr.update(visible=False)
    # æ˜¾ç¤ºæ‰“æ ‡å™¨è®¾ç½®
    if evt.value in taggers:
        # if evt.value == "æ ‡ç­¾é»‘åå•":
        #     evt.value = "dropper"
        if evt.value == "jsonè§£æ":
            evt.value = "anal"
        updates[globals()[f"tagger_{evt.value}_settings"]] = gr.update(visible=True)
        # print(evt.value, tagger_dropper_settings.visible)
    # updates[globals()[f"wd14_use_blacklist"]] = gr.update(value=wd14_use_blacklist.value)
    # updates[globals()[f"ml_use_blacklist"]] = gr.update(value=ml_use_blacklist.value)
    # updates[globals()[f"tagger_dropper_settings"]] = gr.update(visible=tagger_dropper_settings.visible)
    return updates


def blacklist_settings_ctrl(evt: gr.SelectData):
    updates = {}
    if evt.selected:
        updates[tagger_dropper_settings] = gr.update(visible=True)
    else:
        updates[tagger_dropper_settings] = gr.update(visible=False)
    return updates


def custom_blacklist_ctrl(evt: gr.SelectData):
    if evt.selected:
        dropper_update = {globals()[f"drop_custom_setting"]: gr.update(visible=False)}
    else:
        dropper_update = {globals()[f"drop_custom_setting"]: gr.update(visible=True)}
    return dropper_update


def pixiv_setting_ctrl(evt: gr.SelectData):
    if evt.index == 1:
        update = {globals()[f"pixiv_settings"]: gr.update(visible=True)}
    else:
        update = {globals()[f"pixiv_settings"]: gr.update(visible=False)}
    return update


def color_picker_ctrl(evt: gr.SelectData):
    if evt.selected:
        update = {globals()[f"areaf_color"]: gr.update(visible=False)}
    else:
        update = {globals()[f"areaf_color"]: gr.update(visible=True)}
    return update


def save_output_ctrl():
    global output_cache
    if has_image(output_cache):
        update = {globals()[f"save_output"]: gr.update(interactive=True)}
    else:
        update = {globals()[f"save_output"]: gr.update(interactive=False)}
    return update


def saving_output(dataset_name):
    global output_cache
    count = 0
    if dataset_name.endswith("_processed"):
        process_dir = f"dataset/{dataset_name}"
    else:
        process_dir = f"dataset/{dataset_name}_processed"
    if has_image(output_cache):
        os.makedirs(process_dir, exist_ok=True)
        anyfiles = os.listdir(process_dir)
        # print(" - å¼€å§‹ä¿å­˜è¿è¡Œç»“æœ")
        for anyfile in anyfiles:
            os.remove(f"{process_dir}/{anyfile}")
        for i, sv in enumerate(tqdm(output_cache, file=sys.stdout, desc=" - å¼€å§‹ä¿å­˜è¿è¡Œç»“æœ", ascii="â–‘â–’â–ˆ")):
            sv.save(f"{process_dir}/{dataset_name}_{i+1}.png")
            count = count+1
        output_cache = []
        return "å·²ä¿å­˜ "+str(count)+" å¼ å›¾ç‰‡è‡³"+process_dir+"æ–‡ä»¶å¤¹"


def tagging_main(dataset_name, ttype, wd14_tagger, wd14_general_thre, wd14_character_thre, wd14_weight, wd14_overlap, ml_real_name, ml_thre, ml_scale, ml_weight, ml_ratio, ml_overlap, need_black, drop_presets, drop_custom, exists_txt, del_json):
    global output_cache
    images = dataset_getImg(dataset_name)[0]
    img_name = dataset_getImg(dataset_name)[1]
    result = []
    if ttype == taggers[0]:
        # print(" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†")
        for img, name in tzip(images, img_name, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†"):
            result = get_wd14_tags(img, wd14_tagger, wd14_general_thre, wd14_character_thre, wd14_overlap)
            if result[2]:
                result = tags_to_text(result[1], include_score=wd14_weight)+', '+tags_to_text(result[2], include_score=wd14_weight)  # features and chars
            else:
                result = tags_to_text(result[1], include_score=wd14_weight)
            if need_black:
                # print(result)
                result = str(str(drop_blacklisted_tags([result], drop_presets, drop_custom))[2:-2])
            if result:
                name = name.replace(".txt", "").replace(".jpg", "").replace(".png", "").replace(".jpeg", "")
                if os.path.isfile(f'dataset/{dataset_name}/{name}.txt'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'dataset/{dataset_name}/{name}.txt', f'{dataset_name}/{name}_backup.txt')
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'a+') as tag:
                            tag.write(result)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                else:
                    with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                        tag.write(result)
    elif ttype == taggers[1]:
        # print(" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†")
        for img, name in tzip(images, img_name, file=sys.stdout, ascii="â–‘â–’â–ˆ", desc=" - æ•°æ®æ‰“æ ‡å¼€å§‹å¤„ç†"):
            result = get_mldanbooru_tags(img, ml_real_name, ml_thre, ml_scale, ml_ratio, ml_overlap)
            result = tags_to_text(result, include_score=ml_weight)
            if need_black:
                result = str(str(drop_blacklisted_tags([result], drop_presets, drop_custom))[2:-2])
            # print(result)
            if result:
                name = name.replace(".txt", "")
                if os.path.isfile(f'dataset/{dataset_name}/{name}.txt'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'dataset/{dataset_name}/{name}.txt', f'{dataset_name}/{name}_backup.txt')
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'a+') as tag:
                            tag.write(result)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                            tag.write(result)
                else:
                    with open(f'dataset/{dataset_name}/{name}.txt', 'w') as tag:
                        tag.write(result)
    elif ttype == taggers[2]:
        json_files = glob.glob(f'dataset/{dataset_name}/.*.json')
        # print(" - æ ‡ç­¾è§£æå¼€å§‹å¤„ç†")
        for json_file in tqdm(json_files, file=sys.stdout, desc=" - æ ‡ç­¾è§£æå¼€å§‹å¤„ç†", ascii="â–‘â–’â–ˆ"):
            with open(json_file, 'r') as f:
                jdata = json.load(f)
            danbooru_data = jdata.get('danbooru', {})
            tag_json_general = danbooru_data.get('tag_string_general', '')
            tag_json_character = danbooru_data.get('tag_string_character, ')
            if tag_json_general:
                tag_json_general = tag_json_general.replace(' ', ', ')
            if tag_json_character:
                tag_json_character = tag_json_character.replace(' ', ', ')
            if tag_json_general is None and tag_json_character is None:
                output_cache = []
                return "æ— æ ‡ç­¾"
            elif tag_json_general is None:
                tag_json = tag_json_character
            elif tag_json_character is None:
                tag_json = tag_json_general
            else:
                tag_json = f"{tag_json_general}\n{tag_json_character}\n"
            if need_black:
                tag_json = str(str(drop_blacklisted_tags([tag_json], drop_presets, drop_custom))[2:-2])
            txtfile_name = json_file.replace('.', '', 1).replace('_meta.json', '.txt')
            if tag_json_general or tag_json_character:
                if os.path.isfile(f'{txtfile_name}'):
                    if exists_txt == "å¤åˆ¶æ–‡ä»¶":
                        os.rename(f'{txtfile_name}', f'{txtfile_name}'.replace('.txt', '_backup.txt'))
                        with open(f'{txtfile_name}', 'w') as f:
                            f.write(tag_json)
                    elif exists_txt == "å¿½ç•¥æ–‡ä»¶":
                        pass
                    elif exists_txt == "é™„åŠ æ ‡ç­¾":
                        with open(f'{txtfile_name}', 'a+') as f:
                            f.write(tag_json)
                    elif exists_txt == "è¦†ç›–æ–‡ä»¶":
                        with open(f'{txtfile_name}', 'w') as f:
                            f.write(tag_json)
                else:
                    with open(f'{txtfile_name}', 'w') as f:
                        f.write(tag_json)
                if del_json:
                    os.remove(json_file)


# @gr.StateHandler
def pre_rating_limit(rating):
    updates = {}
    # print(evt.index)
    # print(pre_rating)
    # print(rating)
    if not rating:
        updates[download_button] = gr.update(interactive=False)
    else:
        updates[download_button] = gr.update(interactive=True)
    return updates


# @gr.StateHandler
def illu_source_limit(i_source):
    updates = {}
    if not i_source:
        updates[illu_button] = gr.update(interactive=False)
    else:
        updates[illu_button] = gr.update(interactive=True)
    return updates


def save_settings(p_token, f_cookie):
    global cfg
    cfg['pixiv_token'] = p_token
    cfg['fanbox_cookie'] = f_cookie
    with open('config.json', 'w') as f:
        json.dump(cfg, f, ensure_ascii=False, indent=4)
    load_settings()
    # åˆ·æ–°è®¾ç½®é¡µé¢
    return "å·²ä¿å­˜è®¾ç½®"


def load_settings():
    global cfg
    if os.path.getsize('config.json') > 0:  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        with open('config.json', 'r') as config:
            cfg = json.load(config)
    else:
        cfg = {}


def pixiv_login():
    global pyapi
    global cfg
    pyapi = AppPixivAPI()
    for _ in range(3):
        try:
            pyapi.auth(refresh_token=cfg.get('pixiv_token', ''))
            print("[ä¿¡æ¯] - Pixivå·²ç™»å½•")
            break
        except PixivError:
            time.sleep(10)
        if not cfg.get('pixiv_token', ''):
            print("[è­¦å‘Š] - Pixivç™»å½•å¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰è®¾ç½®è®¿é—®ä»¤ç‰Œ")
            break
    else:
        print("[è­¦å‘Š] - Pixivç™»å½•å¤±è´¥ï¼Œå·²å°è¯•ä¸‰æ¬¡ï¼Œè¯·å‰å¾€è®¾ç½®æ£€æŸ¥åˆ·æ–°ä»¤ç‰Œï¼Œå¹¶å°è¯•é‡æ–°ç™»å½•")


parser = argparse.ArgumentParser()
parser.add_argument("--host", type=str, default="127.0.0.1")
parser.add_argument("--port", type=int, default=7862)
parser.add_argument("--share", type=bool, default=False)
args = parser.parse_args()

# ä¸»ç•Œé¢
with gr.Blocks(css="style.css", analytics_enabled=False) as iblock:
    # è¯»å–é…ç½®æ–‡ä»¶
    global cfg
    # cfg = {}
    load_settings()
    # ç™»å½•pixiv
    global pyapi
    pixiv_login()
    output_cache = []
    quicksettings = gr.Row(elem_id="quicksettings")
    with quicksettings:
        dataset_dropdown = gr.Dropdown(ref_datasets(True), label="å½“å‰æ•°æ®é›†", value=ref_datasets(True)[0], container=True, show_label=True, interactive=True, elem_id='dataset_dropbar')
        ref_datasets_button = gr.Button("ğŸ”„", elem_id='refresh_datasets')
    with gr.Tab("æ•°æ®è·å–"):
        with gr.Tab("å›¾ç«™"):
            source = gr.Radio(['Danbooru', 'Pixiv', 'Zerochan', 'è‡ªåŠ¨'], label='é€‰æ‹©å›¾ç«™', value='Danbooru')
            char_name = gr.Textbox(label='è§’è‰²åç§°', value='', placeholder='å¡«å…¥è§’è‰²å')
            pre_min_size = gr.Textbox(label="æœ€å°å°ºå¯¸", value="600", interactive=True)
            pre_background = gr.ColorPicker(label="èƒŒæ™¯è‰²", value="#FFFFFF", interactive=True)
            pre_class = gr.CheckboxGroup(["ç´ æ", "æ¼«ç”»", "3D"], label="é£æ ¼è¿‡æ»¤", value=None, type="index", interactive=True)
            pre_rating = gr.CheckboxGroup(["å¥å…¨", "r15", "r18"], label="è¯„çº§è¿‡æ»¤", value=["å¥å…¨"], type="index", interactive=True)
            pre_crop_person = gr.Checkbox(label="è£å‰ªäººç‰©", value=False, interactive=True)
            pre_auto_tagging = gr.Checkbox(label="è‡ªåŠ¨æ‰“æ ‡", value=False, interactive=True)
            with gr.Column(visible=False) as pixiv_settings:
                pixiv_no_ai = gr.Checkbox(label="éAIç”Ÿæˆ", interactive=True, value=False)
            source.select(pixiv_setting_ctrl, None, [pixiv_settings])
            dl_count = gr.Textbox(label="ä¸‹è½½æ•°é‡", value='10', placeholder="æ— ä¸Šé™")
            # dl_count = gr.Slider(1, 1001, step=1, value=10, label="ä¸‹è½½æ•°é‡", elem_id='dl_count')
            # save_path = gr.Textbox(label='ä¿å­˜è·¯å¾„', value='dataset', placeholder='è‡ªåŠ¨åˆ›å»ºå­æ–‡ä»¶å¤¹')
            download_button = gr.Button("è·å–å›¾ç‰‡", variant="primary", interactive=True)
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("å¯¹äºå•å›¾ç«™ï¼Œå¡«å…¥è¦æœç´¢çš„ä»»ä½•å†…å®¹ä»¥è·å–å¯¹åº”æ ‡ç­¾å›¾ç‰‡\n"
                            "å¯¹äºè‡ªåŠ¨å›¾ç«™æºï¼Œå¿…é¡»å¡«å…¥ä¸€ä¸ªè§’è‰²å\n"
                            "æ‰€æœ‰å›¾ç«™æ”¯æŒå¤šå†…å®¹é¡ºåºçˆ¬å–ï¼Œç”¨åŠè§’é€—å·åˆ†éš”ï¼Œå¦‚\"é“ƒå…°,é¦™é£æ™ºä¹ƒ\"\n"
                            "ä¿å­˜çš„å›¾ç‰‡ä¼šä»¥æœç´¢å†…å®¹è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæ•°æ®é›†ï¼Œè·å–å®Œæˆååˆ·æ–°æ•°æ®é›†å³å¯æŸ¥çœ‹")
            pre_rating.change(pre_rating_limit, [pre_rating], [download_button])
        with gr.Tab("ç”»å¸ˆ"):
            illu_name = gr.Textbox(label="ç”»å¸ˆå", placeholder="å®Œæ•´ç”»å¸ˆå")
            with gr.Row():
                # illu_get_pixiv = gr.Checkbox(label="Pixiv", value=True, interactive=True)
                # illu_get_fanbox = gr.Checkbox(label="Fanbox", value=False, interactive=True)
                illu_get_source = gr.CheckboxGroup(["Pixiv", "Fanbox"], label="è·å–æ¸ é“", value=["Pixiv"], type="index", interactive=True)
            illu_button = gr.Button("è·å–ä½œå“", variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("ä»…æ”¯æŒpixiv fanbox ç›®å‰\n"
                            "å…³äºå®Œæ•´ç”»å¸ˆåï¼šè¦å†™ç”»å¸ˆåœ¨pixivå¯¹åº”çš„åå­—ï¼Œä¸å¯ä»¥å†™fanboxä¸Šçš„è‹±æ–‡å")
            illu_get_source.change(illu_source_limit, [illu_get_source], [illu_button])
    with gr.Tab("æ•°æ®å¢å¼º"):
        with gr.Accordion("ä¸‰é˜¶åˆ†å‰²"):
            stage_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
        with gr.Accordion("å·®åˆ†è¿‡æ»¤"):
            cluster_threshold = gr.Slider(0, 1, label="é˜ˆå€¼", step=0.1, value=0.45, interactive=True)
            cluster_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("å·®åˆ†æ£€æµ‹ï¼šLPIPSï¼ˆæ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼‰ ï¼Œå…¨ç§°ä¸ºLearned Perceptual Image Patch "
                            "Similarityï¼Œæ˜¯ä¸€ç§ç”¨äºè¯„ä¼°å›¾åƒç›¸ä¼¼æ€§çš„åº¦é‡æ–¹æ³•ã€‚åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡æ¯”è¾ƒå›¾åƒä¹‹é—´çš„æ·±åº¦ç‰¹å¾è¯„ä¼°å®ƒä»¬çš„ç›¸ä¼¼æ€§\n "
                            "LPIPSä½¿ç”¨äº†é¢„è®­ç»ƒçš„åˆ†ç±»ç½‘ç»œï¼ˆå¦‚AlexNetæˆ–VGGï¼‰æ¥æå–å›¾åƒçš„ç‰¹å¾ã€‚ç„¶åè®¡ç®—ä¸¤ä¸ªå›¾åƒç‰¹å¾ä¹‹é—´çš„ä½™å¼¦è·ç¦»ï¼Œ"
                            "å¹¶å¯¹æ‰€æœ‰å±‚å’Œç©ºé—´ç»´åº¦çš„è·ç¦»è¿›è¡Œå¹³å‡ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªå€¼ï¼Œç”¨äºè¡¨ç¤ºä¸¤ä¸ªå›¾åƒä¹‹é—´çš„æ„ŸçŸ¥å·®å¼‚ã€‚\n"
                            "*ä¼šè¿”å›å»é™¤å·®åˆ†åçš„å›¾ç‰‡ç»“æœ"
                            "![cluster](file/markdown_res/lpips_full.plot.py.svg)")
        with gr.Accordion("äººç‰©åˆ†ç¦»"):
            seg_scale = gr.Slider(32, 2048,label="ç¼©æ”¾å¤§å°", info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸", step=32, value=1024, interactive=True)
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("äººç‰©åˆ†ç¦»\n"
                            "*ä¼šè¿”å›èƒŒæ™¯ä¸ºé€æ˜çš„äººç‰©å›¾ç‰‡ç»“æœ\n"
                            "æŸ¥é˜…skytntçš„[å¤æ‚åŠ¨æ¼«æŠ åƒ](https://github.com/SkyTNT/anime-segmentation/)")
            seg_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
        # with gr.Accordion("äººç‰©æ£€æµ‹"):
        #     ccip_level = gr.Checkbox(label="ä½¿ç”¨é«˜ç²¾åº¦", value=True, interactive=True)
        #     ccip_model = gr.Dropdown(["v0", "v1", "v1.1"], label="æ¨¡å‹é€‰æ‹©", value="v1.1", interactive=True)
        #     ccip_infer = gr.Slider(32, 2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
        #     ccip_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step=0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
        #     ccip_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
        #     ccip_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
        #     with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
        #         gr.Markdown("è§’è‰²æ£€æµ‹ï¼šCCIPï¼ˆå¯¹æ¯”è§’è‰²å›¾åƒé¢„è®­ç»ƒï¼‰ä»åŠ¨æ¼«è§’è‰²å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè®¡ç®—ä¸¤ä¸ªè§’è‰²ä¹‹é—´çš„è§†è§‰å·®å¼‚ï¼Œå¹¶ç¡®å®šä¸¤ä¸ªå›¾åƒæ˜¯å¦"
        #                     "æç»˜ç›¸åŒçš„è§’è‰²ã€‚![ccip](file/markdown_res/ccip_full.plot.py.svg)"
        #                     "æ›´å¤šä¿¡æ¯å¯æŸ¥é˜… [CCIPå®˜æ–¹æ–‡æ¡£](https://deepghs.github.io/imgutils/main/api_doc/metrics/ccip.html).")
        with gr.Accordion("é¢éƒ¨æ£€æµ‹"):
            faced_level = gr.Checkbox(value=True, label="ä½¿ç”¨é«˜ç²¾åº¦", interactive=True)
            faced_model = gr.Dropdown(["v0", "v1", "v1.3", "v1.4"], label="æ¨¡å‹é€‰æ‹©", value="v1.4", interactive=True)
            faced_infer = gr.Slider(32,2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
            faced_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step= 0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
            faced_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("##é¢éƒ¨æ£€æµ‹"
                            "æ¥è‡ªimgutilsæ£€æµ‹æ¨¡å—"
                            "###æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ")
            faced_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
        with gr.Accordion("å¤´éƒ¨æ£€æµ‹"):
            headd_level = gr.Checkbox(value=True, label="ä½¿ç”¨é«˜ç²¾åº¦", interactive=True)
            headd_infer = gr.Slider(32,2048, label="ç¼©æ”¾å¤§å°", interactive=True, step=32, value=640, info="å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„ç¼©æ”¾å°ºå¯¸")
            headd_conf = gr.Slider(0.01, 1, label="æ£€æµ‹é˜ˆå€¼", interactive=True, value=0.25, step=0.01, info="ç½®ä¿¡åº¦é«˜äºæ­¤å€¼çš„æ£€æµ‹ç»“æœä¼šè¢«è¿”å›")
            headd_iou = gr.Slider(0.01, 1, label="é‡å é˜ˆå€¼", interactive=True, value=0.7, step=0.01, info="é‡å åŒºåŸŸé«˜äºæ­¤é˜ˆå€¼å°†ä¼šè¢«ä¸¢å¼ƒ")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("##å¤´éƒ¨æ£€æµ‹"
                            "æ¥è‡ªimgutilsæ£€æµ‹æ¨¡å—"
                            "###æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ")
            headd_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
        with gr.Accordion("æ–‡æœ¬æ£€æµ‹"):
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("æ–‡æœ¬æ£€æµ‹\n"
                            "ç”¨ocrçš„æ–¹å¼æ£€æµ‹æ–‡æœ¬çš„æ¨¡å—\n"
                            "æ­¤åŠŸèƒ½ä¼šè¿”å›ä¸€ä¸ªåŒºåŸŸç»“æœï¼Œè€Œä¸æ˜¯å›¾ç‰‡ç»“æœ\n"
                            "æ­¤åŠŸèƒ½ç»“æœè´¨é‡å·®ï¼Œä¸å»ºè®®ä½¿ç”¨")
            textd_button = gr.Button("å¼€å§‹æ£€æµ‹", variant="primary")
        with gr.Accordion("åŒºåŸŸå¡«å……"):
            areaf_isRandom = gr.Checkbox(label="éšæœºé¢œè‰²", value=True, interactive=True)
            areaf_color = gr.ColorPicker(label="è‡ªå®šä¹‰é¢œè‰²", value="#00FF00", visible=not areaf_isRandom.value)
            areaf_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("æ¥æ”¶è¾“å‡ºåçš„ç»“æœè¿›è¡Œæ‰“ç ã€‚\n"
                            "è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥å¡«å……...")
            areaf_isRandom.select(color_picker_ctrl, None, [areaf_color])
        with gr.Accordion("åŒºåŸŸæ¨¡ç³Š"):
            areab_radius = gr.Slider(1, 20, label="æ¨¡ç³Šå¼ºåº¦", value=4, interactive=True, step=1)
            areab_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("æ¥æ”¶è¾“å‡ºåçš„ç»“æœè¿›è¡Œæ‰“ç ã€‚\n"
                            "è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥æ¨¡ç³Š...")
        with gr.Accordion("åŒºåŸŸå‰ªè£"):
            crop_hw_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("å°†è¿è¡Œç»“æœä¸­çš„åŒºåŸŸè¿›è¡Œå‰ªè£ã€‚\n"
                            "è¿è¡Œç»“æœå†…æœ‰åŒºåŸŸä¿¡æ¯ï¼Œæ‰å¯ä»¥å‰ªè£...")
        with gr.Accordion("è‡ªé€‚åº”å‰ªè£"):
            crop_trans_button = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
            crop_trans_thre = gr.Slider(0.01, 1, label="å®¹å·®é˜ˆå€¼", value=0.7, step=0.01)
            crop_trans_filter = gr.Slider(0, 10, label="ç¾½åŒ–", value=5, step=1)
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("å°†æ•°æ®é›†ä¸­çš„é€æ˜å›¾ç‰‡è¿›è¡Œè‡ªé€‚åº”å‰ªè£ã€‚\n"
                            "ä¸å¯¹è¿è¡Œç»“æœä¸­çš„å†…å®¹è¿›è¡Œæ“ä½œã€‚")
    with gr.Tab("æ‰“æ ‡å™¨"):
        taggers = ["wd14", "mldanbooru", "jsonè§£æ"]
        tagger_type = gr.Dropdown(taggers, value=taggers[0], label="æ‰“æ ‡å™¨", allow_custom_value=False, interactive=True)
        with gr.Column(visible=tagger_type.value == taggers[0]) as tagger_wd14_settings:
            wd14_tagger_model = gr.Dropdown(["SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT"], value="ConvNextV2", label="æ‰“æ ‡æ¨¡å‹", interactive=True)
            wd14_general_threshold = gr.Slider(0.01, 1, value=0.35, label="æ™®é€šæ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
            wd14_character_threshold = gr.Slider(0.01, 1, value=0.85, label="è§’è‰²æ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
            wd14_format_weight = gr.Checkbox(label="å†™å…¥æƒé‡", value=False, interactive=True)
            wd14_drop_overlap = gr.Checkbox(value=True, label="ç²¾ç¡®æ‰“æ ‡", interactive=True)
            # wd14_use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
        with gr.Column(visible=tagger_type.value == taggers[1]) as tagger_mldanbooru_settings:
            ml_use_real_name = gr.Checkbox(value=False, label="æ ‡ç­¾é‡å®šå‘", info="ç”±äºåœ¨Deepdanbooruè®­ç»ƒåï¼ŒDanbooruç½‘ç«™ä¸Šçš„è®¸å¤šæ ‡ç­¾éœ€è¦é‡å‘½åå’Œé‡å®šå‘ï¼Œå› æ­¤åœ¨æŸäº›åº”ç”¨åœºæ™¯ä¸­å¯èƒ½æœ‰å¿…è¦ä½¿ç”¨æœ€æ–°çš„æ ‡ç­¾åç§°ã€‚")
            ml_threshold = gr.Slider(0.01, 1, value=0.7, label="æ ‡ç­¾é˜ˆå€¼", step=0.01, interactive=True)
            ml_size = gr.Slider(32, 1024, value=448, step=32, label="ç¼©æ”¾å¤§å°", interactive=True, info="å°†ç¼©æ”¾åçš„å›¾åƒä¼ é€’ç»™æ¨¡å‹æ—¶çš„å¤§å°")
            ml_keep_ratio = gr.Checkbox(value=False, label="ä¿æŒæ¯”ä¾‹", info="ä¿æŒè®­ç»ƒé›†å›¾åƒçš„åŸå§‹æ¯”ä¾‹", interactive=True)
            ml_format_weight = gr.Checkbox(label="å†™å…¥æƒé‡", value=False, interactive=True)
            ml_drop_overlap = gr.Checkbox(value=True, label="ç²¾ç¡®æ‰“æ ‡", interactive=True)
            # ml_use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
        with gr.Column(visible=tagger_type.value == taggers[2]) as tagger_anal_settings:
            with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("ç”¨æ­¤è„šæœ¬è·å–çš„å›¾ç‰‡é™„æœ‰jsonæ–‡ä»¶\n"
                            "ä½¿ç”¨æ­¤æ‰“æ ‡å™¨ä»¥ä»ä¸­æå–tag\n"
                            "æ­¤åŠŸèƒ½ä¸ä¼šæ£€æŸ¥å›¾ç‰‡ï¼Œè€Œæ˜¯ä»æ‰€æœ‰å¯èƒ½çš„jsonæ–‡ä»¶ä¸­æå–tag")
            anal_del_json = gr.Checkbox(value=False, label="åˆ é™¤json", interactive=True)
        use_blacklist = gr.Checkbox(label="ä½¿ç”¨é»‘åå•", value=True, interactive=True)
        with gr.Column(visible=use_blacklist.value) as tagger_dropper_settings:
            drop_use_presets = gr.Checkbox(value=True, label="ä½¿ç”¨åœ¨çº¿é»‘åå•", info="è·å–åœ¨çº¿é»‘åå•ï¼Œæ¥è‡ªalea31435", interactive=True)
            with gr.Column(visible=not drop_use_presets.value, elem_id="drop_custom_setting") as drop_custom_setting:
                drop_custom_list = gr.Dropdown(ref_customList(True), value=ref_customList(True)[0], label="è‡ªå®šä¹‰é»‘åå•", elem_id="custom_list", interactive=True, info="é»‘åå•è·¯å¾„cfgs/blacklist/")
                drop_ref_button = gr.Button("ğŸ”„", elem_id='refresh_custom_list')
        op_exists_txt = gr.Dropdown(["å¤åˆ¶æ–‡ä»¶", "å¿½ç•¥æ–‡ä»¶", "è¦†ç›–æ–‡ä»¶", "é™„åŠ æ ‡ç­¾"], value="é™„åŠ æ ‡ç­¾", info="å¯¹äºå·²å­˜åœ¨æ ‡ç­¾ï¼Œæ‰“æ ‡å™¨çš„è¡Œä¸º", show_label=False, interactive=True)
        tagger_button = gr.Button("æ‰“æ ‡", variant="primary")
        # tagger_type.select(tagger_chooser_ctrl, None, [globals()[f'tagger_{("dropper" if tagger == "æ ‡ç­¾é»‘åå•" else tagger)}_settings'] for tagger in taggers])
        tagger_type.select(tagger_chooser_ctrl, None, [globals()[f'tagger_{("anal" if tagger == "jsonè§£æ" else tagger)}_settings'] for tagger in taggers])
        # wd14_use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
        # ml_use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
        use_blacklist.select(blacklist_settings_ctrl, None, [tagger_dropper_settings])
        drop_use_presets.select(custom_blacklist_ctrl, None, [drop_custom_setting])
    with gr.Tab("PLoRAè®­ç»ƒ"):
        min_step = gr.Textbox(label="æœ€å°æ­¥æ•°", value='', placeholder='ä¸å¡«å†™å°†è‡ªåŠ¨è®¡ç®—')
        epoch = gr.Slider(1, 100, label="Epoch", value=10)
        batch_size = gr.Slider(1, 64, label="Batch Size", value=4, step=1)
        train_button = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary")
        with gr.Accordion("æƒé‡åˆå¹¶", open=True):
            with gr.Column(elem_id="convert_lora_steps") as convert_lora_steps:
                convert_step = gr.Dropdown(ref_runs(dataset_dropdown.value, True), value=ref_runs(dataset_dropdown.value, True)[0] if ref_runs(dataset_dropdown.value, True) else [], label="æ­¥æ•°", info="åˆå¹¶å¯¹åº”æ­¥æ•°çš„æƒé‡æ–‡ä»¶", elem_id="convert_list", multiselect=False, interactive=True)
                convert_ref_button = gr.Button("ğŸ”„", elem_id='convert_ref_button')
            convert_weights_button = gr.Button("å¼€å§‹åˆå¹¶", variant="primary")
        with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("è®­ç»ƒè¯¦ç»†è¯´æ˜..ä»€ä¹ˆçš„")
    with gr.Tab("è´¨é‡éªŒè¯"):
        with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("soon...")
    with gr.Tab("è®¾ç½®"):
        with gr.Tab("Pixiv"):
            pixiv_token = gr.Textbox(label="åˆ·æ–°ä»¤ç‰Œ", placeholder="ä¸å¡«å†™å°†æ— æ³•è®¿é—®Pixiv", interactive=True, value=cfg.get('pixiv_token', ''))
            pixiv_get_token = gr.Button("å‰å¾€æŸ¥è¯¢", interactive=True)
            with gr.Accordion("ä»¤ç‰Œè¯´æ˜", open=False):
                gr.Markdown("è·å–Pixivå›¾ç‰‡éœ€è¦åˆ·æ–°ä»¤ç‰Œ\n"
                            "ç”¨æ³•ï¼šç‚¹å‡»`å‰å¾€è·å–`ï¼Œå°†æ‰“å¼€Pixivç½‘é¡µï¼ŒæŒ‰F12å¯ç”¨å¼€å‘è€…æ§åˆ¶å°ï¼Œé€‰æ‹©`ç½‘ç»œ/Network`ï¼Œç‚¹å‡»å·¦ä¾§ç¬¬ä¸‰ä¸ªæŒ‰é’®`ç­›é€‰å™¨`ï¼Œ"
                            "ç­›é€‰`callback?`ç‚¹å‡»ç»§ç»­ä½¿ç”¨æ­¤è´¦å·ç™»å½•ï¼Œæ­¤æ—¶é¡µé¢ä¼šè·³è½¬ï¼Œå¼€å‘è€…æ§åˆ¶å°ä¼šå‡ºç°ä¸€æ¡è¯·æ±‚ï¼Œç‚¹å‡»å®ƒï¼Œè¿›å…¥`æ ‡å¤´`"
                            "å¤åˆ¶`code=`åçš„å†…å®¹ï¼Œå¡«å…¥åå°ï¼ˆé»‘çª—å£ï¼‰æŒ‰å›è½¦ï¼Œåå°å°†è¿”å›ä½ çš„refresh token\n"
                            "æ‰“å¼€webuiæ—¶ä¼šå°è¯•è‡ªåŠ¨ç™»å½•ï¼Œå¦‚æœå¤±è´¥è¯·å°è¯•ä¸‹æ–¹ç™»å½•æŒ‰é’®ï¼Œéœ€è¦å…ˆå¡«å†™åˆ·æ–°ä»¤ç‰Œå¹¶ä¿å­˜\n"
                            "æ§åˆ¶å°ä¸­å¯ä»¥çœ‹åˆ°ç™»å½•ä¿¡æ¯\n"
                            "å–æ¶ˆæŸ¥è¯¢è¯·åœ¨åå°æŒ‰ctrl+c")
            # settings_list = [pixiv_token]
            pixiv_manual_login = gr.Button("å°è¯•ç™»å½•", interactive=True)
        with gr.Tab("Fanbox"):
            fanbox_cookie = gr.Textbox(label="Cookie", lines=13, placeholder="ä¸å¡«å†™å°†æ— æ³•è·å–Fanboxå†…å®¹", interactive=True, value=cfg.get('fanbox_cookie', ''))
            fanbox_get_cookie = gr.Button("å‰å¾€æŸ¥è¯¢", interactive=True)
            with gr.Accordion("Cookieè¯´æ˜", open=False):
                gr.Markdown("è·å–Fanboxå›¾ç‰‡éœ€è¦Kemonoç½‘ç«™Cookie\n"
                            "Cookieæ ¼å¼ï¼š{xxx}ï¼Œåä¸ºsessionçš„cookie\n"
                            "å…·ä½“æ“ä½œï¼šä½¿ç”¨EditThisCookieæµè§ˆå™¨æ‰©å±•\n"
                            "è¿›å…¥Kemonoç½‘ç«™ï¼Œå¯¼å‡ºcookieï¼Œå°†cookieç²˜è´´åˆ°è®¾ç½®ä¸­ï¼Œåˆ é™¤ç¬¬ä¸€é¡¹å’Œç¬¬ä¸‰é¡¹ï¼Œ\n"
                            "åˆ é™¤[]å¤§æ‹¬å·ï¼Œåªä¿ç•™åä¸ºsessionçš„cookie{xxx}å³å¯")
        setting_save_button = gr.Button("ä¿å­˜", interactive=True, variant="primary")
        with gr.Accordion("ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("æˆ‘åªæ˜¯ä¸ªæ‰“é…±æ²¹çš„...")
    with gr.Column(elem_id="output"):
        message_output = gr.Textbox(label='è¿è¡Œç»“æœ', elem_id="message_output")
        save_output = gr.Button("ğŸ’¾", elem_id="save_output", interactive=False)
        message_output.change(save_output_ctrl, [], save_output)
    # dl_count.change(None, )
    setting_save_button.click(save_settings, [pixiv_token, fanbox_cookie], [message_output])
    pixiv_manual_login.click(pixiv_login, [], [])
    pixiv_get_token.click(get_ref_token, [], [])
    fanbox_get_cookie.click(get_fanbox_cookie, [], [])
    download_button.click(download_images, [source, char_name, pre_min_size, pre_background, pre_class, pre_rating, pre_crop_person, pre_auto_tagging, dl_count, pixiv_no_ai], [message_output], scroll_to_output=True)
    ref_datasets_button.click(ref_datasets, [], [dataset_dropdown])
    stage_button.click(three_stage, [dataset_dropdown], [message_output])
    drop_ref_button.click(ref_customList, [], [drop_custom_list])
    convert_ref_button.click(ref_runs, [dataset_dropdown], [convert_step])
    convert_weights_button.click(convert_weights, [dataset_dropdown, convert_step], [message_output])
    cluster_button.click(clustering, [dataset_dropdown, cluster_threshold], [message_output], scroll_to_output=True)
    seg_button.click(img_segment, [dataset_dropdown, seg_scale], [message_output], scroll_to_output=True)
    # ccip_button.click(person_detect, [dataset_dropdown, ccip_level, ccip_model, ccip_infer, ccip_conf, ccip_iou], [message_output])
    faced_button.click(face_detect, [dataset_dropdown, faced_level, faced_model, faced_infer, faced_conf, faced_iou], [message_output], scroll_to_output=True)
    headd_button.click(head_detect, [dataset_dropdown, headd_level, headd_infer, headd_conf, headd_iou], [message_output], scroll_to_output=True)
    textd_button.click(text_detect, [dataset_dropdown], [message_output], scroll_to_output=True)
    train_button.click(run_train_plora, [dataset_dropdown, dataset_dropdown, min_step, batch_size, epoch], [message_output], scroll_to_output=True)
    areaf_button.click(area_fill, [dataset_dropdown, areaf_isRandom, areaf_color], [message_output], scroll_to_output=True)
    areab_button.click(area_blur, [dataset_dropdown, areab_radius], [message_output], scroll_to_output=True)
    crop_hw_button.click(crop_hw, [dataset_dropdown], [message_output], scroll_to_output=True)
    crop_trans_button.click(crop_trans, [dataset_dropdown, crop_trans_thre, crop_trans_filter], [message_output], scroll_to_output=True)
    tagger_button.click(tagging_main, [dataset_dropdown, tagger_type, wd14_tagger_model, wd14_general_threshold, wd14_character_threshold, wd14_format_weight, wd14_drop_overlap, ml_use_real_name, ml_threshold, ml_size, ml_format_weight, ml_keep_ratio, ml_drop_overlap, use_blacklist, drop_use_presets, drop_custom_list, op_exists_txt, anal_del_json], [message_output], scroll_to_output=True)
    illu_button.click(download_illust, [illu_name, illu_get_source], [message_output], scroll_to_output=True)
    save_output.click(saving_output, [dataset_dropdown], [message_output])
    iblock.title = "å°è‹¹æœwebui"

if __name__ == "__main__":
    # log.info(f"Server started at http://{args.host}:{args.port}")
    if sys.platform == "win32":
        webbrowser.open(f"http://{args.host}:{args.port}")
    iblock.launch(server_port=args.port, server_name=args.host, share=args.share)
